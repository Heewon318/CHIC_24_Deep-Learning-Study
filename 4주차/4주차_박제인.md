## 1. Seq2Seq(sequence-to-sequence)

: sequence를 입력받고 sequence를 출력하는 모델.

- ‘입력 sequence’를 ‘source sequence’라고 하며
- ‘정답 sequence’를 ‘target sequence’라고 한다.
- **대표 분야**:
    - 기계 번역(Machine Translation): 번역하려는 문장을 입력받아 번역된 문장을 출력한다.
    - 챗봇: 질문을 입력받아 답변을 출력한다.
    - 내용 요약(Text Summarization), Speech to Text, Image Captioning, 말의 어투를 변경하는 등 입력된 sequence를 다른 도메인의 sequence로 변경되는 곳에 많이 쓰인다.
- **구조**
    - seq2seq를 크게 보면 many-to-many 형태라고 볼 수 있다. 입력된 sequence를 끝까지 읽고 정보를 압축한 뒤 압축된 정보를 바탕으로 출력 sequence를 구성한다. seq2seq에서 입력된 문장을 끝까지 읽고 정보를 압축하는 역할을 하는 모듈을 ‘Encoder’라고 한다. 압축된 정보를 바탕으로 출력 sequence를 만드는 역할을 하는 모듈을 ‘Decoder’라고 한다. 그리고 압축된 정보를 ‘Context vector’라고 부른다.
- **단점**
    - 한정된 길이의 벡터(마지막 시점의 hidden state vector)만을 이용해 Encoder의 입력 sequence 정보를 담기 때문에 sequence의 길이가 길수록 시작 시점에 가까운 정보가 유실될 수 있다. (= seq2seq 구조는 한정된 길이의 벡터를 이용해 입력 sequence의 모든 정보를 담기 때문에 입력 정보의 유실이 일어난다.)
    - RNN 모델이 지닌 구조적인 한계점인 long-term dependency 문제가 있을 수 있다.
    - LSTM도 long-term depedency 문제를 완벽하게 극복한 것은 아니다.
 
      
## 2. Attention

: Attention 메커니즘은 기계 번역, 이미지 캡셔닝 등 다양한 시퀀스 처리 문제에서 성능을 향상시키기 위해 도입된 기술이다. Attention 메커니즘은 모델이 입력 시퀀스의 중요한 부분에 더 집중할 수 있게 하여, 시퀀스 길이가 길어지더라도 효과적으로 정보를 처리할 수 있도록 한다. 

### 주요 개념

1. **Attention Score**
    - 입력 시퀀스의 각 요소가 출력 시퀀스의 각 요소에 미치는 영향을 수치화한 값이다. 일반적으로 쿼리(Query), 키(Key), 값(Value)로 표현.
    - Query: 현재 처리 중인 출력 시퀀스의 요소
    - Key: 입력 시퀀스의 각 요소
    - Value: 입력 시퀀스의 각 요소에 대한 값
2. **Alignment Score**
    - Query와 Key 간의 유사도를 계산하여 Attention Score를 생성합니다. 이 유사도는 내적(Dot Product), 스케일드 내적(Scaled Dot Product), 또는 행렬 곱(Matrix Multiplication) 등으로 계산할 수 있다.
3. **Attention Weight**
    - Alignment Score를 Softmax 함수를 통해 정규화하여 얻는 값이다. 이 값은 입력 시퀀스의 각 요소가 현재 출력 시퀀스 요소에 얼마나 중요한지를 나타낸다.
4. **Context Vector**
    - Attention Weight와 Value의 가중합으로 생성된다. 이 벡터는 현재 출력 시퀀스를 예측하는 데 사용된다.

### 원리

1. **Query, Key, Value 설정**
    - 입력 시퀀스의 각 요소는 고정된 길이의 벡터로 변환된다. 이 벡터들은 Query, Key, Value로 사용.
2. **Alignment Score 계산**
    - Query와 Key 간의 유사도를 계산하여 Alignment Score를 생성. 이 과정은 입력 시퀀스의 각 요소가 현재 출력 시퀀스 요소에 얼마나 중요한지 결정.
3. **Attention Weight 계산**
    - Alignment Score를 Softmax 함수를 통해 정규화하여 각 입력 요소의 중요도를 나타내는 Attention Weight를 계산.
4. **Context Vector 생성**
    - Attention Weight와 Value의 가중합으로 Context Vector를 생성. 이 Context Vector는 출력 시퀀스를 예측하는 데 사용.

### Self-Attention (또는 Intra-Attention)

: Self-Attention은 시퀀스 내의 모든 요소가 서로에게 주목하게 하는 메커니즘이다. 이는 특히 Transformer 모델에서 사용되며, 각 단어가 문맥의 다른 단어들과의 관계를 학습하게 합한다.

### Multi-Head Attention

: Multi-Head Attention은 단일 Attention 메커니즘을 병렬로 여러 개 사용하는 방식이다. 

1. **다수의 Head 생성**:
    - 여러 개의 Query, Key, Value를 생성하여 각 Head마다 독립적으로 Attention을 수행.
2. **병렬 Attention 수행**:
    - 각 Head에서 독립적으로 Attention을 수행하여 각각의 Context Vector를 생성.
3. **결합 및 선형 변환**:
    - 각 Head에서 생성된 Context Vector를 결합하고 선형 변환을 통해 최종 출력으로 만든다.

### 장점

- **장기 의존성 문제 해결**: Seq2seq 모델에서 긴 시퀀스를 처리할 때 발생하는 정보 손실 문제를 해결한다.
- **병렬 처리**: Transformer 모델의 Self-Attention은 병렬 처리가 가능하여, 모델의 학습 속도와 성능을 크게 향상시킨다.
- **유연성**: Attention 메커니즘은 다양한 입력 길이에 유연하게 대응할 수 있다.

## Seq2Seq와 Attention의 공통점
- **목적**: 둘 다 시퀀스 데이터를 처리하여, 입력 시퀀스에서 출력 시퀀스를 생성하는 데 사용.
- **구조**: 둘 다 인코더-디코더 구조를 기반으로 하며, 인코더는 입력 시퀀스를 압축된 표현으로 변환하고, 디코더는 이 표현을 사용하여 출력 시퀀스를 생성.

## Seq2Seq와 Attention의 차이점

- **컨텍스트 벡터**
  - **Seq2seq**: 고정 길이의 컨텍스트 벡터를 사용하여 전체 입력 시퀀스를 요약.
  - **Attention**: 입력 시퀀스의 각 요소에 대해 가변 길이의 가중치를 적용, 더 많은 정보를 활용.

- **정보 처리 방식**
  - **Seq2seq**: 입력 시퀀스 전체를 하나의 컨텍스트 벡터로 요약, 긴 시퀀스의 경우 정보 손실 가능.
  - **Attention**: 입력 시퀀스의 모든 요소를 가중합으로 고려, 필요한 부분에 더 집중 가능.

- **성능**
  - **Seq2seq**: 긴 시퀀스를 처리할 때 성능 저하 가능.
  - **Attention**: 긴 시퀀스도 효율적으로 처리, 성능 향상.

- **복잡성**
  - **Seq2seq**: 상대적으로 단순한 구조.
  - **Attention**: 추가적인 계산 단계와 메커니즘으로 인해 더 복잡.

이러한 차이점으로 인해 Attention 메커니즘은 Seq2seq 모델의 한계를 극복하고, 더 나은 성능을 제공할 수 있다!

**질문** 
Q. Seq2seq와 Attention 기반 모델의 성능을 평가하는 주요 지표들은 무엇인가? 이러한 지표들이 모델의 어떤 특성을 측정하며, 각 지표의 장단점은 무엇인가?
  
