## ❓질문1

Attention Machanism을 여러 분야에서 활용 가능할 것 같은데 어떤 부분들이 있을까요?

### 답변 정리

<img width="719" alt="image" src="https://github.com/user-attachments/assets/9df3ef03-4bbe-4755-9d39-35eebe01fe9a">

## ❓질문2
1. attention score와 weight의 차이
2. attention 알고리즘에서 encoder hidden vector와 decoder hidden vector 내적값이 음수 일 때 반의어라고 볼 수 있나?

### 답변 정리
1. score 에 exp()를 해 양수 값으로 모두 만든 후 전체 합으로 나눠줘서 총 합이 1이 되도록 한 게 weight이다.
2. 그렇다.
