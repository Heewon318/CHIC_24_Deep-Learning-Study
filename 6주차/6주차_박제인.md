# 6주차_이미지 분류

- 454페이지부터 504페이지까지의 내용

### 1. **이미지 분류의 개요**

- **이미지 분류**는 이미지에 대한 클래스 레이블을 할당하는 작업이다. 딥러닝의 발전으로 이미지 분류는 매우 정밀하게 발전했으며, 다양한 애플리케이션에서 중요한 역할을 하고 있다.
- 대표적인 이미지 분류 모델로는 Convolutional Neural Networks (CNNs)가 있으며, 이는 이미지 데이터의 공간적 정보를 효과적으로 활용할 수 있도록 설계되었다.

### 2. **Convolutional Neural Networks (CNN)**

- CNN은 이미지 처리에 특화된 딥러닝 아키텍처로, **Convolutional Layer**, **Pooling Layer**, **Fully Connected Layer**로 구성됨.
- **Convolutional Layer**: 이미지의 특징을 추출하는 계층으로, 필터를 사용하여 입력 이미지에서 특정 패턴을 감지.
- **Pooling Layer**: 공간적 크기를 줄이고, 불필요한 정보를 제거하며, 계산 효율성을 높임.
- **Fully Connected Layer**: 최종적인 분류 작업을 수행하는 계층으로, 이전 계층에서 추출된 특징을 활용해 이미지를 특정 클래스에 매핑.

### 3. **활성화 함수와 손실 함수**

- **활성화 함수**는 신경망에서 비선형성을 추가하여 모델이 복잡한 데이터를 학습할 수 있도록 한다. 일반적으로 ReLU (Rectified Linear Unit)가 많이 사용된다.
- **손실 함수**는 모델의 예측과 실제 값 사이의 차이를 측정하는 함수. 이미지 분류에서는 주로 **Cross-Entropy Loss**가 사용된다.

### 4. **이미지 분류 모델 학습**

- 모델 학습 과정은 역전파(backpropagation)와 경사 하강법(gradient descent)을 통해 가중치를 조정하는 방식으로 이루어진다.
- 학습 과정에서는 훈련 데이터셋, 검증 데이터셋을 활용하여 모델의 성능을 평가하고, 과적합(overfitting)을 방지하기 위한 다양한 정규화 기법이 사용된다.

### 5. **데이터 증강과 전이 학습**

- 데이터 증강(data augmentation)은 학습 데이터를 인위적으로 늘려 모델이 다양한 변형에 대해 견고하게 학습할 수 있도록 돕는 기법.
- 전이 학습(transfer learning)은 사전 학습된 모델을 기반으로 새로운 과제를 학습하는 방식으로, 일반적으로 학습 데이터를 충분히 확보하기 어려운 상황에서 효과적이다.

### 6. **현대적인 CNN 아키텍처**

- **LeNet, AlexNet, VGGNet, ResNet** 등의 각 모델은 특정 이미지 분류 문제에 대한 성능을 극대화하기 위해 설계된 다양한 구조적 특징을 가지고 있다.
- 특히 **ResNet**은 **Residual Learning**을 도입하여 매우 깊은 신경망에서도 효과적으로 학습할 수 있도록 한 혁신적인 모델이다. => 잔차학습 기법으로 기울기소실(저하) 문제 해결, 수렴 속도 단축
    
    ResNet의 기본 Residual Block(잔차 블록) 구조
    
    1. **첫 번째 Convolutional Layer**: 3×3 필터와 ReLU 활성화 함수를 사용하는 Convolutional Layer.
    2. **두 번째 Convolutional Layer**: 또 다른 3×3 필터와 ReLU 활성화 함수를 사용하는 Convolutional Layer.
    3. **Skip Connection (Identity Mapping)**: 입력 x가 두 번째 Convolutional Layer의 출력에 더해짐.

 ## Q. ResNet이 쓰이기 적절하지 않은 경우는 언제일까?

### 1. **작거나 간단한 데이터셋**

- **ResNet은 매우 깊은 신경망 구조**이기 때문에, 간단한 문제나 작은 데이터셋에서는 오히려 과적합(overfitting)의 위험이 있다. 예를 들어, CIFAR-10과 같은 작은 이미지 데이터셋이나 복잡도가 낮은 데이터셋에서는 더 간단한 모델(예: VGG, LeNet)이 더 적합할 수 있다.

### 2. **실시간 또는 자원 제한적인 환경**

- **ResNet은 연산이 복잡하고, 메모리와 계산 리소스를 많이 사용한**다. 따라서 실시간 처리가 요구되거나, 모바일 기기나 임베디드 시스템처럼 자원이 제한된 환경에서는 ResNet이 비효율적일 수 있다. 이 경우에는 MobileNet, SqueezeNet 등 경량화된 모델이 더 적합하다.

### 3. **모델 해석이 중요한 경우**

- **ResNet은 매우 깊고 복잡한 구조**이기 때문에, 모델의 내부 작동 방식을 해석하거나 설명하는 것이 어려울 수 있다. 만약 모델의 결정 과정을 명확하게 이해하거나 설명해야 하는 상황이라면, 더 단순한 네트워크나 설명 가능한 인공지능 모델이 더 적합할 수 있다.

### 4. **전이 학습이 필요하지 않은 경우**

- ResNet은 전이 학습(transfer learning)에 매우 유용하지만, **만약 전이 학습이 필요하지 않고 처음부터 학습할 충분한 데이터가 있다면**, 더 단순한 모델을 처음부터 학습하는 것이 더 효율적일 수 있다.

### 5. **응용 도메인 특성**

- ResNet은 이미지 분류 작업에서 뛰어난 성능을 발휘하지만, **특정 도메인에서는 다른 특화된 모델이 더 좋은 성능**을 낼 수 있다. 예를 들어, 자연어 처리에서는 Transformer 기반 모델들이 더 적합하며, 시계열 데이터에서는 LSTM이나 GRU 같은 순환 신경망(RNN)이 더 적합할 수 있다.

### 6. **장기간 학습이 불가능한 경우**

- **ResNet은 깊이와 복잡성으로 인해 학습에 시간이 많이 걸린다.** 만약 제한된 시간 내에 학습을 완료해야 하거나, 빠른 프로토타입이 필요한 경우, ResNet보다 더 단순하고 빠르게 학습할 수 있는 모델이 더 적합할 수 있다.

### 7. **정밀도보다는 속도가 중요한 경우**

- ResNet은 높은 정확도를 제공하지만, **속도보다는 정확도에 중점을 둔다.** 만약 실시간 응답이 필요하거나, 정확도보다 처리 속도가 더 중요한 애플리케이션에서는 ResNet보다 경량화된 네트워크가 더 적합할 수 있다.
        
       
