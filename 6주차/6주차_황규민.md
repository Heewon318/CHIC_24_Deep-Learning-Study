# 이미지 분류
이미지에서 객체나 장면 같은 요소를 인식하고 분류하는 알고리즘을 의미

단일 클래스 분류: 이미지 내 서로 다른 여러 객체가 존재하더라도 하나의 대표 클래스로 이진분류

다중 클래스 분류: 이미지 내 대표를 여러 클래스 중에서 분류

다중 레이블 분류: 이미지 내 여러 클래스를 예측

# AlexNet

2012년 개최된 ILSVRC대회에서 우승을 차지한 합성곱 신경망 구조 모델로 합성곱 신경망 모델을 부흥시킴

이미지 특징 추출 합성곱과 최대값 풀링 계층 활용, 완전 연결 계층을 통해 클래스를 분류

- 순전파 과정에서 특징 맵의 차원 수는 증가하고, 크기는 감소함
- 합성곱 모델의 특징은 차원 수가 늪어나면 모델의 표현력이 증가
- 특징 맵의 크기를 줄여서 연상량을 줄임

## LeNet-5와 AlexNet

중요 차이점

입력 이미지 크기, 활성화 함수(ReLU), 풀링 방식의 변경(Max pooling), 드롭아웃

# VGG(Visual Geometry Group)

구글넷은 인셉션 모듈(Inception module)을 사용해 다양한 필터 크기와 풀링 작업으로 병렬 합성곱 연산을 수행, 전역 특징과 지역 특징을 모두 포착해 성능을 높이지만 복잡한 구조로 활용이 잘 안됨

## AlexNet과 VGG-16

둘 다 이미지넷 데이터로 학습

VGG-16은 작은 필터를 여러 번 적용해 모델 매개변수 수를 감소시키고 활성화 함수를 더 많이 적용해 비선형성 증가시킴 

## 모델 구조 및 데이터 시각화

ToTensor 객체가 (H W C)에서 (C H W) 형태로 변환하기 때문에 다시 (H W C)형태로 변환

## 미세 조정 및 모델 학습

# ResNet(Residual Network)

2015년 MS 연구팀에서 발표한 합성곱 신경망 모델

VGG의 깊은 신경망 구조로 기울기 소실문제를 ResNet은 잔차연결, 항등 사상, 잔차 블록 등을 통해 해결

- 더 깊은 구조의 딥러닝이 등장

## ResNet의 특징

기본 구조는 입력층, 합성곱 계층, 배치 정규화 계층, 활성화 함수, 잔차 블록, 평균값 풀링 계층, 완전 연결 계층, 출력층

단축 연결은 이전 계층의 출력값을 현재 계층의 입력값과 더해 이전 계층에서 발생한 정보를 계속 전달하여 기울기를 유지할 수 있음

### 잔차 학습

모델이 입력과 출력 사잉의 차이(Residual)만 학습하게 하는 방법, 이전 계층에서 학습된 결과를 그대로 가져와 더해줌.

### 잔차 연결

Residual Connection이란 스킵 연결(Skip Connection), 단축 연결(Shortcut)이라고 부르고 입력값이 신경망 계층을 통과한 후 출력값에 더해지는 연결을 의미

### 병목 블록

레즈넷의 깊은 모델 구조를 유지하면서 연산량을 줄이기 위해 병목 블록(Bottleneck Block) 추가

1*1 합성곱 계층을 통해 특징 맵의 차원 수를 줄임, 그 후 1*1 합성곱 계층을 통해 특징 맵의 차원 수를 증가시킴

## 모델 구현

# Grad-CAM(Gradient-weighted Class Activation Mapping)

설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI) 기술 중 하나로, 딥러닝 모델의 내부 동작 원리를 시각화 하는 방법

클래스 활성화 맵과 유사하지만, 전역 평균 풀링을 사용하지 않고 마지막 합성곱 계층에서 역전파를 통해 클래스에 대한 중요도를 계산
