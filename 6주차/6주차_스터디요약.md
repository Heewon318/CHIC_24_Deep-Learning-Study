## ❓질문1

🙄 최댓값 풀링이 왜 평균값 풀링보다 성능이 좋지?

### 답변 정리

1 특징 강조: 최댓값 풀링은 중요한 특징들을 강조하는 효과가 있는 반면, 평균값 풀링은 이런 중요한 요소들을 희석해버린다.

2 노이즈 제거: 최댓값 풀링은 작은 값이나 노이즈를 무시하고 중요한 특징만을 강조하기 때문에 잡음에 덜 민감!

## ❓질문2

ResNet을 할때 원래는 이전 시점의 출력값을 현재 출력값이랑 잔차 연결하는데 이전 시점말고 더 과거의 출력값이랑 잔차연결하게 되면 어떻게 돼?

### 답변 정리

1. 정보 결합의 다양성 증가: 더 과거의 출력값을 잔차로 연결하면, 모델이 더 넓은 범위의 정보(더 과거의 특성)를 결합할 수 있게 됩니다. 이는 모델이 더 넓은 문맥에서 정보를 고려하도록 도와줄 수 있습니다.

2. 복잡한 학습 패턴: 레이어 간 연결이 멀어지면 잔차 연결의 효과가 복잡해질 수 있습니다. 이는 모델이 학습하는 패턴이 더 복잡해지는 것을 의미할 수 있으며, 학습이 잘 이루어진다면 더 정교한 특성 추출이 가능할 수 있습니다. 그러나 동시에 모델이 더 학습하기 어려워질 수도 있습니다.

3. 기울기 흐름 변화: 잔차 연결이 더 과거로 이어지면, 기울기가 흐르는 경로가 길어져서 기울기 소실 문제가 다시 발생할 가능성이 높아질 수 있습니다. 이는 ResNet의 주요 장점을 일부 상실하게 만드는 결과로 이어질 수 있습니다.

4. 모델의 해석 어려움 증가: 모델의 구조가 더 복잡해지면서, 어떤 출력이 어떤 입력에 의한 것인지 해석하기가 더 어려워질 수 있습니다. 이는 모델의 해석 가능성을 저하시킬 수 있습니다.

## ❓질문3
입력 이미지의 크기를 이야기해주는데, 책에서는 224를 사용했다고 나와있는데 제가 알고 있던 보편적인 이미지 크기는 256이어서 궁금했습니다! 224, 227, 256 모두 찾아보았습니다!

### 답변 정리

- 227x227

AlexNet의 원래 논문에서 사용된 입력 이미지 크기는 227x227입니다. 이 크기는 이미지 전처리 과정에서 최종적으로 AlexNet 모델에 입력되는 이미지 크기입니다.

- 224x224

PyTorch와 같은 딥러닝 프레임워크에서 제공하는 사전 학습된 AlexNet 모델은 보통 224x224 크기의 이미지를 사용합니다. 이는 다양한 딥러닝 프레임워크에서 표준으로 사용되는 크기이며, ResNet 등 다른 모델과 일관성을 유지하기 위해 사용됩니다.

- 256x256의 역할

1. 전처리 단계

Resize(256x256): 원본 이미지의 크기가 다를 수 있기 때문에, 첫 번째로 이미지를 256x256 크기로 리사이즈합니다. 이 크기로 이미지를 맞추는 것은 이후 단계에서 이미지의 특정 부분을 크롭하는 작업을 용이하게 합니다.

2. 무작위 크롭(Random Cropping)

이미지가 256x256 크기로 조정된 후, 그 이미지에서 무작위로 224x224 크기의 패치를 잘라내어 모델에 입력합니다. 이 과정은 데이터 증강의 일환으로, 모델이 다양한 위치와 크기의 패치를 보게 만들어 일반화 능력을 향상시킵니다.
