# 파이토치 심화
### 과대적합과 과소적합
- 과대적합 : 모델이 훈련 데이터는 우수하게 예측하지만 새로운 데이터는 제대로 예측하지 못함. -> 오차가 큼(일반화 능력 저하). 모델 구조가 너무 복잡하기 때문.
- 과소적합 : 훈련 데이터도 예측 못하고 새로운 데이터도 제대로 예측 못함.  -> 모델 구조가 너무 단순하기 때문.
- 과대적합과 과소적합은 모델의 성능을 저하시킴. => 훈련데이터와 새로운 데이터 둘 다에 대해 우수한 성능 보이려면 낮은 편향과 낮은 분산 가져야 함!!
- 문제 해결 방법 : 모델 변경 또는 모델 구조 개선, 학습 데이터 수 늘리기, 피처 엔지니어링, 배치 정규화, 가중치 초기화, 정칙화  등
  
### 편향-분산 트레이드오프
  - 훈련데이터와 새로운 데이터 둘 다에 대해 우수한 성능 보이려면 낮은 편향과 낮은 분산 가져야 하는데 편향과 분산은 반비례한다.
  - 편향이 높으면 과소적합, 분산이 높으면 과대적합 문제가 발생함.
  - 모델의 성능을 높이려면 편향과 분산의 균형을 맞추어야 한다.

### 과대적합과 과소적합 문제 해결 방법 중 심화 학습한 내용
### 1. 배치 정규화(Batch Normalization)
- 배치 정규화는 신경망이 학습하는 과정을 더 빠르고 안정적으로 만들기 위해 각 미니배치의 데이터에 대해 활성화 값을 정규화하여 데이터의 분포를 조정하는 방법이다.
 *  미니 배치(mini-batch)는 큰 데이터를 작은 덩어리로 나눈 것을 말한다. 예를 들어, 1000장의 이미지가 있으면, 이 이미지를 한 번에 처리하지 않고 100장씩 10번에 나눠서 처리하는 것이다. 이 작은 덩어리 하나를 미니 배치라고 한다.
- 쉽게 말해, 신경망이 더 잘 배우도록 데이터의 값을 "평균 0, 분산 1"로 맞춰주는 과정이다.
- 배치 정규화 과정 : 1. 미니 배치 선택: 데이터 전체가 아닌 작은 덩어리(미니 배치)를 선택한다. 2. 평균과 분산 계산: 미니 배치의 평균과 분산을 계산한다. 평균은 데이터의 중심값을, 분산은 데이터가 얼마나 퍼져 있는지를 나타냄. 3. 정규화: 각 데이터에서 평균을 빼고 분산으로 나눠서 데이터를 조정한다. 이렇게 하면 데이터의 중심이 0이 되고, 퍼짐 정도가 1이 된다. 4. 학습 가능한 매개변수 적용: 이렇게 조정된 데이터에 특별한 값(γ, β)을 더해준다. 이 값들은 신경망이 학습하면서 최적의 값을 찾아간다.
- 배치 정규화는 모델의 계층마다 평균과 분산을 조정해 내부 공변량 변화를 줄여 과대적합을 방지한다.
