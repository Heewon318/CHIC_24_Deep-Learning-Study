# 파이토치 심화
### 과대적합과 과소적합
- 과대적합 : 모델이 훈련 데이터는 우수하게 예측하지만 새로운 데이터는 제대로 예측하지 못함. -> 오차가 큼(일반화 능력 저하). 모델 구조가 너무 복잡하기 때문.
- 과소적합 : 훈련 데이터도 예측 못하고 새로운 데이터도 제대로 예측 못함.  -> 모델 구조가 너무 단순하기 때문.
- 과대적합과 과소적합은 모델의 성능을 저하시킴. => 훈련데이터와 새로운 데이터 둘 다에 대해 우수한 성능 보이려면 낮은 편향과 낮은 분산 가져야 함!!
- 문제 해결 방법 : 모델 변경 또는 모델 구조 개선, 학습 데이터 수 늘리기, 피처 엔지니어링, 배치 정규화, 가중치 초기화, 정칙화  등
  
### 편향-분산 트레이드오프
![title](https://blog.kakaocdn.net/dn/bT2iuZ/btqyg76Nl3T/kPpkJ8zKTDzefTF7dTX2dK/img.png)  
  - 훈련데이터와 새로운 데이터 둘 다에 대해 우수한 성능 보이려면 낮은 편향과 낮은 분산 가져야 하는데 편향과 분산은 반비례한다.
  - 편향이 높으면 과소적합, 분산이 높으면 과대적합 문제가 발생함.
  - 모델의 성능을 높이려면 편향과 분산의 균형을 맞추어야 한다.

### 과대적합과 과소적합 문제 해결 방법 
### 1. 배치 정규화(Batch Normalization)
![title](https://i.ytimg.com/vi/zwGcVrdyCBg/hq720.jpg?sqp=-oaymwE7CK4FEIIDSFryq4qpAy0IARUAAAAAGAElAADIQj0AgKJD8AEB-AG-B4AC0AWKAgwIABABGGUgYyhYMA8=&rs=AOn4CLBFj7HnhVu_uHEh03zZtmEKndZl-Q)   
- 배치 정규화는 신경망이 학습하는 과정을 더 빠르고 안정적으로 만들기 위해 각 미니배치의 데이터에 대해 활성화 값을 정규화하여 데이터의 분포를 조정하는 방법이다.
 *  미니 배치(mini-batch)는 큰 데이터를 작은 덩어리로 나눈 것을 말한다. 예를 들어, 1000장의 이미지가 있으면, 이 이미지를 한 번에 처리하지 않고 100장씩 10번에 나눠서 처리하는 것이다. 이 작은 덩어리 하나를 미니 배치라고 한다.
- 쉽게 말해, 신경망이 더 잘 배우도록 데이터의 값을 "평균 0, 분산 1"로 맞춰주는 과정이다.
- 배치 정규화 과정 : 1. 미니 배치 선택: 데이터 전체가 아닌 작은 덩어리(미니 배치)를 선택한다. 2. 평균과 분산 계산: 미니 배치의 평균과 분산을 계산한다. 평균은 데이터의 중심값을, 분산은 데이터가 얼마나 퍼져 있는지를 나타냄. 3. 정규화: 각 데이터에서 평균을 빼고 분산으로 나눠서 데이터를 조정한다. 이렇게 하면 데이터의 중심이 0이 되고, 퍼짐 정도가 1이 된다. 4. 학습 가능한 매개변수 적용: 이렇게 조정된 데이터에 특별한 값(γ, β)을 더해준다. 이 값들은 신경망이 학습하면서 최적의 값을 찾아간다.
- 배치 정규화는 모델의 계층마다 평균과 분산을 조정해 내부 공변량 변화를 줄여 과대적합을 방지한다.
- 내부 공변량 변화(Internal Coveriate Shift)는? ✍️Internal Covariate Shift는 네트워크의 각 Layer나 Activation마다 출력값의 데이터 분포가 Layer마다 다르게 나타나는 현상을 말한다.


### 2. 정규화 종류 비교
![title](https://velog.velcdn.com/images/euisuk-chung/post/43cb32ac-32b0-4c8d-8196-552850ab11d1/image.png)   

### 3. 가중치 초기화
- 모델의 초기 가중치 값을 설정하는 것을 의미
- 최적화할 때 초기 가중치에 따라 모델 최적화에 어려움을 겪게 되는데 모델 매개변수에 적절한 초깃값을 설정하면 기울기 폭주나 기울기 소실 문제를 완화할 수 있음.
#### 가중치 초기화 방법
- 3-1. 가충치 초기화의 매우 간단한 방법은 상숫값으로 초기화하는 것인데 배열 구조의 가중치에서 대칭 파괴 문제가 발생한다. => 초기 가중치 값을 모두 0이나 0.1과 같은 작은 양의 상숫값으로 동일하게 할당한다. ex: 단위행렬 등<br>   
- 3-2. 무작위 값으로 초기화 : 초기 가중치 값을 무작위 값이나 특정 분포 형태(ex:균등 분포, 정규 분포 등)로 초기화하는 것. => 계층이 많아지고 깊어질수록 기울기 소실 현상 발생.<br>   
- 3-3. 제이비어 & 글로럿 초기화 : 제이비어 초기화는 글로럿 초기화라고도 하며 균등 분포나 정규 분포를 사용해 가중치를 초기화하는 방법임. 각 노드의 출력 분산이 입력 분산과 동일하도록 가중치를 초기화함. => 제이비어 초기화는 입력 데이터의 분산이 출력 데이터에서 유지되도록 가중치를 초기화하므로 시그모이드나 하이퍼볼릭 탄젠트를 활성화 함수로 사용하는 네트워크에서 효과적임.<br>   
- 3-4. 
