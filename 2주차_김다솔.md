# 과대적합과 과소적합

- 머신러닝 모델에서 자주 발생하는 문제
- 과대적합: 모델이 훈련 데이터에서는 우수 but, 새로운 데이터 제대로 예측 x
![title](https://www.datarobot.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png)   

- 과소적합: 훈련 데이터, 새로운 데이터 둘 다  성능 😣

### 성능 저하
### 모델 선택 실패
모델을 변경해 문제를 완화할 수 있음.
- 과대적합 -> 모델 구조가 너무 복잡해 훈련 데이터에만 의존하게 되어 성능이 저하됨.
- 과소적합 -> 모델 구조가 너무 단순해 데이터의 특징 제대로 학습하지 못한 경우
### bias-varience trade-off
![title](https://the-examples-book.com/starter-guides/data-science/_images/bias_variance_tradeoff.png)   

낮은 편향 & 낮은 분산 -> 우수한 성능!
- 높은 분산 -> 추청치에 대한 변동 폭 커짐, 데이터가 갖고 있는 노이즈까지 학습에 포함됨 -> 과대적합!
- 높은 편향 -> 항상 일정한 값을 갖게 될 확률 커짐 -> 데이터의 특징을 제대로 학습 x -> 과소적합!
- but, 편향과 분산은 서로 반비례 관계
### 과대적합과 과소적합 문제 해결
- 데이터 수집
학습 데이터 수를 늘림으로써 일반적인 규칙을 더욱 잘 찾을 수 있게 한다.

🙄 학습 데이터를 늘리는 것이 상황에 상관없이 항상 학습의 성능을 향상시키는가?

- 피처 엔지니어링(데이터 변환)
추가적인 데이터 수집이 어려울 경우 기존 학습 데이터에서 변수나 특징을 추출하거나 피처를 더 작은 차원으로 축소하여 강건한 모델을 만든다.


# 배치 정규화
- 내부 공변량 변화를 줄여 과대적합 방지
- 내부 공변량 변화가 발생하면 은닉층에서 다음 은닉층으로 전달될 때 입력값이 균일해지지 않아 가중치가 제대로 갱신 x ->그럼 학습이 불안정해지고 가중치가 일정한 값으로 수렴하기 어렵... 
#### 배치 정규화 방식
[100, 1, 1], [1, 0.01, 0.01]
= [1.4242, -0.7071, -0.7071]
- 배치 정규화를 적용하면 입력이 일반화되고 독립적으로 정규화가 수행되기에 더 빠르게 값을 수렴!
- 입력이 정규화되므로 초기 가중치에 대한 영향 ⬇
- 이미지 분류 모델에 적용시 14배 더 적은 학습으로도 동일한 정확도 달성! ㄷㄷㄷ

# 가중치 초기화
- 모델의 초기 가중치 값(모델 최적화에 완전완전 중요!!!) 설정
