# 과대적합과 과소적합

- 머신러닝 모델에서 자주 발생하는 문제
- 과대적합: 모델이 훈련 데이터에서는 우수 but, 새로운 데이터 제대로 예측 x
![title](https://www.datarobot.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1527613915658.png)   

- 과소적합: 훈련 데이터, 새로운 데이터 둘 다  성능 😣

### 성능 저하
### 모델 선택 실패
모델을 변경해 문제를 완화할 수 있음.
- 과대적합 -> 모델 구조가 너무 복잡해 훈련 데이터에만 의존하게 되어 성능이 저하됨.
- 과소적합 -> 모델 구조가 너무 단순해 데이터의 특징 제대로 학습하지 못한 경우
### bias-varience trade-off
![title](https://the-examples-book.com/starter-guides/data-science/_images/bias_variance_tradeoff.png)   

낮은 편향 & 낮은 분산 -> 우수한 성능!
- 높은 분산 -> 추청치에 대한 변동 폭 커짐, 데이터가 갖고 있는 노이즈까지 학습에 포함됨 -> 과대적합!
- 높은 편향 -> 항상 일정한 값을 갖게 될 확률 커짐 -> 데이터의 특징을 제대로 학습 x -> 과소적합!
- but, 편향과 분산은 서로 반비례 관계
### 과대적합과 과소적합 문제 해결
- 데이터 수집
학습 데이터 수를 늘림으로써 일반적인 규칙을 더욱 잘 찾을 수 있게 한다.

🙄 학습 데이터를 늘리는 것이 상황에 상관없이 항상 학습의 성능을 향상시키는가?

- 피처 엔지니어링(데이터 변환)
추가적인 데이터 수집이 어려울 경우 기존 학습 데이터에서 변수나 특징을 추출하거나 피처를 더 작은 차원으로 축소하여 강건한 모델을 만든다.
- 모델 변경
