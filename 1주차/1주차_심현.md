# 3. 파이토치 기초
## 텐서
### 텐서(Tensor)
텐서란 넘파이 라이브러리와 비슷한 구조로 **배열(Array)** 이나 **행렬(Matrix)** 과 유사한 자료 구조이다. 수학 계산, 선형 대수 연산을 비롯해 **전치(Transposing)**, **인덱싱(Indexing)**, **슬라이싱(Slicing)**, **임의 샘플링(Random Sampling)** 등 다양한 텐서 연산을 진행 할 수 있다.

파이토치에서 텐서를 사용해 모델의 입출력뿐만 아니라 모델의 매개 변수를 부호화(Encoding)하고 GPU를 활용해 연산을 가속화할 수 있다.

넘파이와 파이토치의 차이점은 GPU에서 텐서를 사용하는지 CPU를 사용하는지의 차이이다.

### 텐서의 형태

텐서의 형태로는 여러 형태가 있다.

단일 값 하나는 0차원 텐서로 **스칼라(Scalar)** 의 값을 가진다. 모든 값의 기본 형태로 볼 수 있다.

**벡터(Vector)** 는 [1, 2, 3]과 같은 형태를 가지고 있고 흔히 쓰이는 1차원 리스트와 비슷하다. (N, )의 차원을 가진다..

**행렬(Matirx)** 은 [[1, 2, 3], [4, 5, 6]]의 형태를 가지고 있으며 회색조 이미지를 표현하거나 좌표계로도 활용 될 수 있다. 벡터값들을 하나로 묶은 형태로 간주하며(N, M)으로 표현 할 수 있다.

**배열(Array)** 은 3차원 이상의 배열을 모두 지칭한다. 배열의 경우 이미지를 표현하기에 가장 적합한 형태를 가지고 있다. 행렬을 세 개 생성해 겹쳐 놓은 구조로 볼 수 있다.

예시로는 이미지의 경우(C, H, W) → 채널, 이미지의 높이, 이미지의 너비를 가질 수 있다.

4차원 배열은 3차원 배열을 하나로 묶은 형태로 이미지 여려개의 묶음으로 볼 수 있다.

예시로는 이미지의 경우(N, C, H, W)로 N은 이미지의 개수이다.

### 텐서 생성

```python
torch.Tensor()
```

이 코드로 텐서를 생성 할 수있다. 텐서는 배열을 생성하는 방식과 동일하다.

1차원 배열은 int 형식으로 할당된다.

2차원 배열은 기본 유형이 float으로 정수형을 할당하더라도 소수점 형태로 변환된 것이다.

### 텐서 속성(Attribute)

텐서의 속성으로는 크게 **형태(Shape)**, **자료형(dtype)**, **장치(device)** 가 존재한다.

형태와 자료형은 넘파이 배열에서 사용하는 형태와 유사하다.

형태는 텐서의 차원을 의미함, 자료형은 텐서에 할당된 데이터 형식을 의미합니다

장치는 텐서의 GPU가속 여부를 의미합니다.

```python
import torch

tensor = torch.rand(1, 2)

print(tensor)
print(tensor.shape)
print(tensor.dtype)
print(tensor.device)
```

```python
#결과

tensor([[0.8522, 0.3964]])
torch.Size([1, 2])
torch.float32
cpu
```

생성된 텐서의 형태로는 1차원으로 2개의 데이터가 있고 float32의 형식을 가집니다.

### 차원 변환

머신러닝 연산 과정이나 입출력 변환 등에 많이 활용됩니다.

넘파이의 차원 변환 방법과 동일합니다.

### 자료형 설정

텐서의 자료형 설정에 입력되는 인수는 torch.*로 입력됩니다.

### 장치 변환

CPU 장치를 이용하는 텐서와 GPU 장치를 이용하는 텐서는 서로 연산이 불가능합니다.

CPU를 사용하는 텐서와 넘파이 배열간 연산은 가능하며, GPU장치를 사용하는 텐서와 넘파이 배열 간 연산은 불가능합니다.

넘파이 배열을 학습에 활용시키려면 GPU장치로 변환 후 데이터 학습이 가능합니다.

### 넘파이 배열의 텐서 변환

넘파이나 다른 라이브러리의 데이터를 파이토치에 활용하려면 텐서 형식으로 변환 해야합니다.

넘파이 배열을 텐서로 변환하는 방법으로는 3가지가 있습니다.

1. torch.tensor에 넘파이 배열을 그대로 입력하기
2. torhc.Tensor에 넘파이 배열을 그대로 입력하기
3. from_numpy 메서드를 통해 변환하는 방법

텐서와 넘파이는 매우 친화적인 구조를 가지고 있어 넘파이 데이터를 별다른 변환 없이 적용 할 수 있습니다.

### 텐서의 넘파이 배열 변환

추런된 결과를 후처리하거나 결과값을 활용 할 때 주로 사용됩니다.

텐서를 넘파이 배열로 변환하는 방법은 numpy 메서드를 통하는 겁니다.

```python
import torch

tensor = torch.cuda.FloatTensor([1, 2, 3])
ndarray = tensor.detach().cpu().numpy()
print(ndarray)
print(type(ndarray))
```

텐서는 기존 데이터 형식과 다르게 학습을 위한 데이터 형식으로 모든 연산을 추적해 기록합니다.

이 기록을 통해 역전파(Backpropagation) 등과 같은 연산이 진행돼 모델 학습이 이루어집니다.

detach  메서드는 현재 연산 그래프에서 분리된 새로운 텐서를 반환 합니다.

새로운 텐서로 생성한 다음에 넘파이 배열로 변환합니다. GPU 장치라면 CPU 장치로 변환한 다음에 넘파이 배열로 변환해야 합니다
## 가설(Hypothesis)
가설이란 어떤 사실을 설명하거나 증명하기 위한 가정으로 두 개 이상의 변수의 관계를 검증 가능한 형태로 기술하여 변수 간의 관계를 예측하는것을 의미합니다.

가설은 어떠한 현상에 대해 이론적인 근거를 토대로 통계적 모형을 구축하며, 데이터를 수집해 해당 현상에 대한 데이터의 정확한 특성을 식별해 검증합니다.

가설은 크게 **연구가설(Research Hypothesis)** 과 **귀무가설(Null Hypothesis)**, **대립가설(Alternative Hypothesis)** 로 나눌 수 있습니다.

연구가설은 연구자가 검증하려는 가설로 귀무가설을 부정하는것으로 설정한 가설을 증명하려는 가설입니다.

귀무가설은 통계학에서 처음부터 벌리 것을 예상하는 가설입니다. 변수 간 차이나 관계가 없음을 통계학적 증거를 통해 증명하려는 가설입니다.

대립가설은 귀무가설과 반대되는 가설로, 귀무가설이 거짓이라면 대안으로 참이 되는 가설입니다.

대립가설과 연구가설은 동일하다고 볼 수 있고, 이를 통해 **통계적 가설 검정(Statistical Hypothesis Test)** 를 진행 할 수 있습니다.

### 머신러닝에서의 가설

머신러닝에서의 가설은 통계적 가설 검정이 되며, 데이터와 변수 간의 관계가 있는지 확률론저긍로 설명하게 됩니다.

머신러닝에서의 가설은 독립변수와 종속변수를 가장 잘 매핑시킬 수 있는 기능을 학습하기 위해 사용됩니다.

독립변수와 종속변수 간의 관계를 가장 잘 근사(Approximation)시키기 위해 사용됩니다.

단일가설(Single Hypothesis)과 가설집합(Hypothesis Set)이 있습니다.

단일 가설은 입력을 출력에 매핑하고 평가하고 예측하는 데 사용할 수 있는 단일 시스템을 의미합니다.

가설집합은 출력에 입력을 매핑하기 위한 가설 공간(Hypothesis Sapce)로 모든 가설을 의미합니다.

단일가설은 $h$로 표현 하고 가설 집합은 $H$로 표현합니다
![Hypothesis Set: 어떠한 문제가 주어졌을 때 무넺를 해결하기 위한 알고리즘 즉 모델아키텍쳐를 의미함
Hypothesis Space: 문제와 답을 이어주는 가설들이 있고, 이 가설들의 집합](image\다운로드.png)

선형회귀를 식으로 나타내면 $y = ax + b$로 표현 할 수 있습니다. $a$는 기울기 $b$는 절편으로 표현합니다.

하지만 머신러닝에서는 $H(x) = Wx + b$로 표현합니다.

$H(x), W, b$는 각각 가설, 가중치(Weight), 편향(Bias)을 의미합니다.

가설은 호귀 분석과 같은 알고리즘을 통해 최적의 가중치와 편향을 찾는 과정을 진행합니다.

학습이 진행될 때마다 기울기와 편향이 지속해서 바뀌게 됩니다.

마지막으로 학습이 된 결과를 모델(Model)이라 부릅니다.

이 모델을 통해 새로운 입력에 대한 결과값을 예측(Prediction)합니다.



### 통계적 가설 검정 사례

대표적인 통계적 가설 검정은 t-검정(t-test)이 있습니다.

쌍체 t-검정(paired t-test)과 비쌍체 t-검정(unpaired t-test)의 두 가지 범주로 더 세분화 할 수 있습니다.

쌍체 t-검정은 동일한 항목 또는 그룹을 두 번 테스트할 때 사용합니다.

쌍체 t-검정이 활용되는 곳: 동일 집단에 대한 약물 치료 전후 효과 검정, 동일 집단에 대한 학습 방법 전후 효과 검정

비쌍체 t-검정은 등분산성을 만족하는 두개의 독립적인 그룹간의 평균을 비교하는데 사용합니다.

등분산성: 분산분석을 통해 설 다른 두개 이상의 집단을 비교하고자 할 때, 기본적으로 해당 집단들이 만족해야되는 조건 중 한가지로 분산이 같음을 의미합니다.

비쌍체 t-검정이 활용되는 곳: 제약 연구에서 서로 다른 두개의 독립적인 집단(실험군, 대조군) 간에 유의미한 차이가 있는지 조사, 서울과 인천의 무작위로 선택 된 참가자 1000명의 평균 통근 거리를 조사

머신러닝에선 비쌍체 t-검정을 사용합니다.

독립변수와 종속변수 사이에 유의미한 차이가 있는지 검증을 합니다.

이때 변수들이 샘플 데이터는 독립항등분포(independent and identivally distributed)를 따릅니다.

통계량(statistic)이 크고  유의 확률(pvalue)이 작다면 귀무가설이 참일 확률이 낮다고 할 수 있습니다.

## 손실 함수(Loss Function)
손실 함수는 단일 셈플의 실제값과 예측값의 차이가 발생했을 때 오차가 얼마인지 계산하는 함수를 의미합니다.

인공 신경망은 실제값과 예측값을 통해 계산된 오찻값을 최소화해 정확도를 높이는 방법으로 학습이 진행됩니다.

각 데이터의 오차를 계산하는데, 이 때 손실 함수를 사용합니다. 손실 함수는 목적 함수(Objective Function), 비용 함수(Cost Function)라고 부르기도 합니다.

목적 함수는 함수값의 결과를 최댓값 또는 최솟값으로 최적화하는 함수입니다.

비용함수는 전체 데이터에 대한 오차를 계산하는 함수입니다.

**$손실함수 \subset 비용함수 \subset 목적함수$** 의 포함 관계를 가집니다.

함수는 모두 오차를 줄이기 위해 사용됩니다.

모집단(Population)에서 X의 값을 해당 수식에 넣어 풀이하면 예측값이 됩니다.

오차는 (실제값 - 예측값)이 됩니다.

오차를 통해 예측값이 얼마나 실제값을 잘 표현하느지 알 수 있습니다.

각가의 데이터에 대한 오차를 확인할 수 있는 방법이어서 가설이 얼마나 실제값을 정확하게 표현하는지 알 수 없습니다.

그러므로 평균 제곱 오차와 같은 방법을 활용해 생성된 가설이 실제값을 얼마나 정확하게 표현하는지 계산해 봅니다.

### 제곱 오차

평균 제곱 오차(Mean Squared Error, MSE) 방법은 제곱 오차(Squared Error, SE)와 오차 제곱(Sum of Squared for Error, SSE)을 활용합니다.

먼저 제곱 오차는 실제값에서 예측값을 뺀 값의 제곱을 의미합니다.

제곱 오차 식

$$
SE = (Y_i - \hat{Y_i})^2
$$

제곱 오차에서 실제값과 예측값을 감산한 값에 제곱을 취합니다. 만약 취하지 않는다면 오차가 양의 방향인지 음의 방향인지를 알 수 있습니다.

하지만 오차에서는 오차의 방향보다는 오차의 크기가 중요한 요소이므로 제곱을 취합니다.

절대값을 취하지 않는 이유는 제곱을 적용하면 오차가 작은 값보다 오차가 큰 값을 더 두드러지게 확대시키기 때문에 오차의 간각을 빠르게 확인 할 수 있습니다.

제곱을 취하기 때문에 오차가 커질수록 데이터마다 오차의 크기르 빠르게 확인할 수 있습니다.

### 오차 제곱합

오차제곱합(Sum of Squared for Error, SSE)은 오차를 모드 더한 값을 의마합니다. 

제곱 오차는 각 데이터의 오차를 의미하므로 가설 또는 모델 자체가 얼마나 정확히 예측하는지 알 수 없습니다.

그러므로 모든 제곱 오차를 더해 하나의 값으로 만들어 가설이나 모델을 평가할 수 있습니다.

오차 제곱합 식

$$
SSE = \sum_{i = 1}^{n}(Y_i-\hat{Y_i})^2
$$

오차 제곱합에서 오찻값들을 제곱하지 않고 모두 더하면 문제가 발생합니다.

오차값이 (-1, 1, -1, 1)과 같은 형태 라면 모든 합계가 0이 되어 오차가 없는 것처럼 보이기 때문입니다.

이러한 현상을 방지하기위해 모든 값을 제곱합 값에 대한 평균으로 오차를 계산합니다.

### 평균 제곱 오차

평균 제곱 오차(Mean Squared Error, MSE) 방법은 단순하게 오차 제곱합에서 평균을 취하는 방법입니다.

오차 제곱합과 평균 제곱 오차는 의미로는 큰 차이가 없지만, 데이터가 많아질수록 오차 제곱합도 동일하게 커집니다.

평균값을 사용하지 않는 경우 오차가 많은 것인지 구분하기가 어려워지므로 모든 데이터의 개수만큼 나누어 평균을 계산합니다.

평균 제곱 오차 식

$$
\begin{matrix}
MSE &=& \frac{1}{n} \sum_{i = 1}^{n}(Y_i-\hat{Y_i})^2
\end{matrix}
$$

평균 제곱 오차는 가설의 품질을 측정할 수 있으며, 오차가 0에 가까워질수록 높은 품질을 갖게 됩니다.

주로 회귀 분석에 많이 사용되는 손실 함수이며, 최대 신호 대 잡음비(Peak Signal-to-noise ratio, PSNR)를 계산할 때도 사용됩니다.

이 값에 루트를 씌우게 된다면 평균 제곱근 오차(Root Mean Squared Error, RMSE)가 됩니다.

루트를 통해 평균 제곱 오차에서 발생한 왜곡을 감소기키면 정밀도(Precision)를 표현하기에 적합한 형태가 됩니다.

하지만 오차에 제곱을 적용해 오차량이 큰 값을 크게 부풀렸기 때문에 왜곡이 발생할 수 있습니다.

### 교차 엔트로피

제곱 오차, 오차 제곱합, 그리고 평균 제곱 오차는 연속형 변수에 사용되는 손실 함수입니다.

- 연속형 변수: 무한한 범위에서 값을 가질 수 잇는 변수. eg) 키, 체중, 온도

반면 이산형 변수는 교차 엔트로피(Cross-Entropy)가 손실 함수로 사용됩니다.

- 이산형 변수: 정수형태의 값을 가지는 변수. eg) 가족 구성원, 학생 수

교차 엔트로피는 실제값의 확률 분포와 예측값의 확률 분포 차이를 계산합니다.

실제 확률 분포를 $y$, 예측된 확률 분포를 $\hat{y}$ 이라고 하면 교차 엔트로피의 수식은 다음을 따릅니다

## 최적화(Optimization)
### 최적화

최적화(Optimization)란 목적 함수의 결괏값을 최적화하는 변수를 찾는 알고리즘을 의미합니다.

손실함수에서 인공 신경망은 오찻값을 최소화하여 학습 데이터에 대한 가설의 정확도를 높이는 방법으로 학습이 진행됐었습니다.

머신러닝은 손실함수를 활용해 최저그이 해볍이나 변수를 찾는 것이 목표입니다.

손실 함수의 값이 최소가 되는 변수를 찾는다면 새로운 데이터에 대해 더 정교한 예측을 할 수 있습니다.

최적화 알고리즘은 실제값과 예측값의 차이를 계산해 오차를 최소로 줄일 수 잇는 가중치와 편향을 계산합니다.

최적의 가중치와 편향을 갖는 가설은 오찻값이 0에 가까운 함수가 됩니다.

가중치와 오차에 대한 도함수의 변화량이 0에 가깝다는 의미 입니다.

즉 가중치와 오차에 대한 그래프의 극값(Extreme Value)이 가설을 가장 잘 표현하는 가중치와 오차가 됩니다.

최적의 가중치에서는 오차가 가장 작으며, 최적의 가중치에서 멀어질수록 오차가 커지는 것을 확인 할 수 있습니다.

가중치와 오차의 그래프에서 기울기(Gradiant)가 0에 가까워질 떄 최적의 가중치를 갖는 것을 알 수 있습니다.

### 경사 하강법

경사 하강법(Gradient Descent)이란 함수의 기울기가 낮은 곳으로 계속 이동시켜 극값에 도달할 때까지 반복하는 알고리즘 입니다.

함수의 기울기가 가장 낮은 곳에 도달하면 최적의 해를 갖게 됩니다.

경사하강법 식

$$
W_0 = Initial \ Value\\
W_{i + 1} = W_i - \alpha\nabla f(W_i)
$$

경사하강법을 포함한 최적화 함수들은 초깃값($W_0$)을 설정해 다음 가중치($W_1, W_2, \cdots$)를 찾습니다.

수식에서 $\nabla f(W_i)$는 앞서 설명한 기울기를 의미합니다.

새로운 가중치는 기울기의 부호(양수, 음수)와 관계없이 기울기가 0인 방향으로 학습이 진행됩니다.

이러한 방식으로 기울기가 0을 갖게 되는 가중치를 찾을 때까지 반복합니다.

그래서 어느 지점에서 시작하더라도 극값을 찾을 수 있게 연산이 진행됩니다.

$\alpha$를 곱해 가중치 결과를 조정하는데, 이 값은 기울기가 한 번에 이동하는 간격(Step Size)을 조정합니다.

### 가중치 갱신 방법

가설은 $\hat{Y_i} = W_i \times x + b_i$로 하고, 손실 함수는 평균 제곱 오차를 적용해 가설과 손실 함수를 정리하면

$$
\hat{Y_i} = W_i \times x + b_i\\
MSE(W, b) = \frac{1}{n} \sum_{i = 1}^{n}(Y_i - \hat{Y_i})^2
$$

경사하강법에 가설과 손실함수를 적용해 가중치를 갱신합니다.

가중치를 갱신할 예정이므로 기울기를 확인하기 위해 $W$에 대해 편미분을 진행합니다.

$$
\begin{matrix}
W_{i+1} &=& W_i - \alpha \frac{\partial}{\partial W} MSE(W, b) \\
&=& W_i - \alpha \frac{\partial}{\partial W} \frac{1}{n} \sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2 \\
&=& W_i - \alpha \frac{\partial}{\partial W} \sum_{i=1}^{n} \left[ \frac{1}{n} \left( Y_i - (W_i \cdot x + b_i) \right)^2 \right] \\
&=& W_i - \alpha \frac{2}{n} \sum_{i=1}^{n} \left[ Y_i - (W_i \cdot x + b_i) \right] \times (-x) \\
&=& W_i - \alpha \times \frac{2}{n} \sum_{i=1}^{n} (Y_i - \hat{Y}_i) \times (-x) \\
&=& W_i - \alpha \times \frac{2}{n} \sum_{i=1}^{n} (\hat{Y}_i - Y_i) \times x \\
&=& W_i - \alpha \times 2 E \left[ (\hat{Y}_i - Y_i) \times x \right]
\end{matrix}
$$

가중치 갱신 방법 일반형

$$
\begin{matrix}
W_{i+1} = W_i - \alpha \times E \left[ (\hat{Y}_i - Y_i) \times x \right]
\end{matrix}
$$

경사하강법을 적용한 새로운 가중치 수식은 $W_i = W_i - \alpha \times E \left[ (\hat{Y}_i - Y_i) \times x \right]$의 형태로 정리 됩니다.

임이의 값으로 설정한 초기 가중치 $W_0$를 위 수식에 입력하면 $W_1$을 구할 수 있고 이 과정을 반복하면 최적의 가중치를 찾을 수 있습니다.

평균을 계산할 때 2의 값은 갱신 과정에서 큰 영향을 미치지 않기 때문에 생략하기도 합니다.

### 학습률

가중치를 갱신할 때 $\alpha$를 곱해 가중치 결과를 조정하는 것을 확인했습니다.

머신러닝에서는 $\alpha$를 학습률(Learning Rate)이라고 합니다.

학습률에 따라 다음 가중치 $(W_1, W_2, \cdots)$의 변화량이 결정됩니다.

이에 따라 최적의 해를 찾기 위한 반복 횟수가 결정됩니다.

만약 적절하지 않은 학습률을 선택하면 너무 많은 반복이 필요하거나, 아무리 많은 반복을 시도해도 최적의 해를 찾기 어려울 수 있습니다.

![Untitled](image\Figure_10.png)

### 최적화 문제

초기값 또는 학습률을 너무 낮거나 높게 잡으면 최적의 가중치를 찾는데 오랜 시간이 걸리거나, 그래프가 발산하여 아예 값을 찾지 못 하는 경우가 생깁니다.

학습률이 너무 낮으면 4차 방정식의 그래프처럼 기울기가 0이 되는 지점인 극값은 최댓값(Global Maximum), 최솟값(Global Minimum), 극댓값(Local Maximum), 극솟값(Local Minimum)으로  구분할 수 있습니다.

초기 가중치나 학습률을 설정할 때 시작점이 적절하지 않거나 학습률이 너무 낮으면 최솟값이 아닌, 극소값에서 가중치가 결정될 수 있습니다.

학습률이 낮으면 극소 지점을 넘지 못 해 지역적 최솟값으로 가중치가 결정됩니다.

또한 안장점(Saddle Point)이 존재하느 함수에서도 적절한 가중치를 찾을 수 없습니다.

![안장점: 어느 방향에서 보면 극소값, 어느 방향에서 보면 극대값이 되는 지점](image\Untitled.png)

안장점: 어느 방향에서 보면 극소값, 어느 방향에서 보면 극대값이 되는 지점

최적화 알고리즘은 경사 하강법처럼 목적 함수가 최적의 값을 찾아갈 수 있도록 최적화되게끔 하는 알고리즘입니다.

어떤 최적화 알고리즘을 사용하느냐에 따라 모델의 정확도가 달라집니다.

최적화 알고리즘은 경사 하강법 이외에도 모멘텀(Momentum), Adagrad(Adaptive Gradient), Adam(Adaptive Moment Estimation)등이 있습니다.

### 단순 선형 회귀: 넘파이

에포크(Epoch)은 인공신경망에서 순전파(Forward Propagation)와 역전파(Back Propagation) 과정 등의 모델 연산을 전체 데이터세트가 1회 통과하는 것을 의미합니다.

각 에포크는 모델이 데이터를 학습하고  가중치를 갱신하는 단계를 나타내며, 여러 에포크를 반보개 모델을 학습시킵니다.

순전파란 입력 데이터를 기반으로 신경망을 따라 입력층부터 출력층까지 차례대로 변수를 계산하고 추론한 결과를 의미합니다.

역전파란 예측값과 실젯값의 오차가 최소회되도록 모델 가중치를 수정하는 것을 의미합니다.

한 번의 에포크는 전체 데이터세트에 대해 순전파/역전파 과정을 수행하여 한번의 학습이 진행되는 것을 의미합니다.

이 에포크 값이 너무 적을 경우 학습이 제대로 되지 않는 과소적합(Underfittiing)이 발생합니다

에포크 값이 너무 많을 경우 과대적합(Overfitting)이 발생할 수 있습니다.

x와 y변수 쌍으로 이루어진 행 데이터를 나눠서 계산하지 않고 전체 데이터를 한번에 연산합니다. 이를 배치(Batch)를 적용한 방법입니다.

배치란 가설이나 모델의 가중치를 갱신할 때 사용하는 데이터의 크기를 의미합니다.

eg) 30개의 데이터를 10000회 학습시킨다면 총 300000회의 반복이 발생합니다. 이러한 반복을 줄이기 위해 30개의 데이터를 하나로 묶어 10000회 반복으로 감소시킬 수 있습니다.

반대로 학습 데이터가 너무 크면 CPU나 GPU에서 한 번에 연한하기 어렵기 때문에 일부 데이터를 나눠서 반복 학습합니다.

가중치를 갱신하기 위해 가중치로 편미분을 진행하면 편미분의 겨로가는 $(\hat{y} - y) \times x$가 됩니다.

편향으로 편미분한다면 $(\hat{y} - y)$입니다.

learning_rate가 0.001일 때는 0.005일 때보다 오차가 더 천천히 감소합니다.

learning_rate가 0.005일 때 초기값으로 매우 큰 값을 주는경우, 오차가 감소 하기는 하지만 매우 많은 학습을 요구합니다.

출력 결과에서 알 수 있듯이 초기값의 설정은 학습에 큰 형향을 끼칩니다.

적절하지 않은 초기값을 할당했을 때 하이퍼파라미터 튜닝을 진행하며, 하이퍼라마미터 튜닝을 통해 원활한 학습을 진행할 수 있습니다.

### 단순 선형 회귀: 파이토치

torch.optim은 최적화 함수가 포함돼있는 모듈입니다.

optim 모듈을 통해 다양한 최적화 함수를 간단하게 사용할 수 있습니다.

확률적 경사 하강법(Stochastic Gradient Descent, SGD)이란 모든 데이터에 대해 연산을 진행하지 않고, 일부 데이터만 계산하여 빠르게 최적화된 값을 찾는 방식입니다.

즉, 미니 배치(Mini-Batch)의 형태로 전체 데이터를 N등분하여 학습을 진행합니다.

변수(params)와 학습률(lr)로 최적화를 적용합니다.

최적화하려는 변수는 역전파 과정을 통해 기울기를 갱신하려는 텐서 변수를 입력하고 학습률은 0보다 큰 값을 할당 합니다.

확률적 경사 하강법의 매개변수에 최적화하려는 변수([weight, bias])와 학습률(learning_rate)을 입력해 weight와 bias가 최적화 됩니다.

신경망(Neural Networks) 패키지를 활용해 모델을 구성 합니다.

신경망 패키지는 torch.nn에 포함 되어있습니다.

신경망 패키지는 네트워그(Net)를 저으이 하거나 자동 미분, 계층 등을 정의할 수 있는 모듈이 포함돼 있습니다.

## 데이터세트와 데이터로더
데이터세트는 데이터의 집합을 의미합니다.

입력값(X)과 결괏괎(Y)에 대한 정보를 제공하거나 일련의 데이터 묶음을 제공합니다.

데이터세트의 구조는 일반적으로 데이터베이스(Database)의 테이블(Table)과 같은 형태로 구성돼있습니다.

데이터세트의 한 패턴을 테이블의 행(Row)으로 간주한다면, 이 행에서 데이터를 불러와 학습을 진행합니다.

데이터를 변형하고 매핑하는 코드를 학습 과정에 직접 반영하면 모듈화(Modularization), 재사용성(Reusable), 가독성(Readability) 등을 떨어트리는 주요 원인이 됩니다.

이러한 현상을 방지하고 코드를 구조적으로 설계할 수 있도록 데이터세트와 데이터로더를 사용합니다.

### 데이터세트(Dataset)

학습에 필요한 데이터 샘플을 정제하고 정답을 저장하는 기능을 제공합니다.

**초기화 메서드(__init__), 호출 메서드(__getitem__), 길이 반환 메서드(__len__)** 를 재정의 하여 활용합니다.

**초기화 메서드(__init__)** 는 입력된 데이터의 전처리 과정을 수행하는 메서드입니다.

새로운 인스턴스가 생성될 때 학습에 사용될 데이터를 선언하고, 학습에 필요한 형태로 변형하는 과정을 진행합니다.

**호출 메서드(__getitem__)** 는 학습을 진행할 때 사용되는 하나의 행을 불러오는 과정으로 볼 수 있습니다.

입력된 색인(index)에 해당하는 데이터 샘플을 불러오고 반환합니다.

초기화 메서드에서 변혀오디거나 개선된 데이터를 가져오며, 데이터 샘플과 정답을 반환합니다.

**길이 반환 메서드(__len__)** 는 학습에 사용된 전체 데이터세트의 개수를 반환 합니다.

이 메서드를 통해 몇개의 데이터로 학습이 진행되는지 확인 할 수 있습니다.

모델 학습을 위해 임의의 데이터세트를 구성할 때 파이토치에서 지원하는 데이터세트 클래스를 상속받아 사용합니다.

새로 정의한 데이터세트 클래스는 현재 시스템에 적합한 구조로 데이터를 전처리해 사용합니다.

### 데이터로더(DataLoader)

데이터세트에 저장된 데이터를 어떠한 방식으로 불러와 활용할지 정의합니다.

학습을 조금 더 원활하게 진행할 수 있도록 **배치 크기(batch_size), 데이터 순서 변경(shuffle), 데이터로드 프로세스 수(num_workers)** 등의 기능을 제공합니다.

**배치크기** 는 학습에 사용되는 데이터의 개수가 매우 많아 한번의 에포크에서 모든 데이터를 메모리에 올릴 수 없을 때 데이터를 나누는 역할을 합니다.

전체 데이터세트에서 배치 크기만큼 데이터 샘플을 나누고, 모든 배치를 대상으로 학습을 완료하면 한 번의 에포크가 완료되는 구조로 볼 수 있습니다.

**데이터 순서 변경** 은 모델이 데이터 간의 관계가 아닌, 데이터의 순서로 학습되는 것을 방지하고자 수행하는 기능입니다.

데이터 샘플과 정답의 매핑 관계는 변경되지 않으며, 행의 순서를 변경하는 개념입니다.

**데이터 로드 프로세스** **수** 는 데이터를 불러올 때 사용할 프로세스의 개수를 의미합니다.

학습을 제외한 코드에서는 데이터를 불러오는 데 시간이 가장 오래 소요됩니다.

이를 최소화하고자 데이터 로드에 필요한 프로세스의 수를 늘릴 수 있습니다.

### 다중 선형 회귀

다준 선형 회귀에서 독립변수는 x1, x2를 의미하며, 종속 변수는 y1, y2를 의미합니다.

$$
y_1 = w_1x_1 + w_2x_2 + b_1\\
y_2 = w_3x_1 + w_3x_2 + b_2
$$

수식으로는 이렇게 표현이 됩니다.

모델 매개변수의 형태는

$$
Weight = \begin{bmatrix}
w_1 & w_2\\
w_3 & w_4
\end{bmatrix}
\\
Bias = \begin{bmatrix}
b_1\\
b_2
\end{bmatrix}
$$

텐서 데이터세트(TensorDataset)는 기본 데이터세트(Dataset) 클래스를 상속받아 재정의된 클래스입니다.

훈련용 데이터로더(train_dataloader)를 반복하여 배치(batch)를 반환합니다.

batch 변수에는 텐서 데이터세트에 입력한 순서로 데이터가 반환됩니다.

즉 batch 변수에는 입력값과 결과값이 포함되어있습니다.

손실(loss) 값을 계산하고, 배치마다 오차(cost)에 손실(loss) 값을 누적해서 더합니다.

오차의 평균값을 계산하기 위해 훈련용 데이터로더(train_dataloader)의 길이만큼 나눕니다.

데이터로더를 활용하면 자연스럽게 배치 구조로 코드가 변경됩니다.

이 경우 학습에 사용되는 데이터의 구조나 형태가 변경되더라도, 실제 학습에 사용되는 코드는 변경되지 않아서 각 모듈에 집중할 수 있습니다.

모델 학습은 오차를 줄이는 방향으로 학습이 진행됩니다.

예상되는 가중치와 편향은 전혀다른 값으로 생성될 수 있지만, 결괏값은 최대한 유사하게 반영됩니다.

실제 환경에서 적용되는 데이터(학습에 사용하지 않은 데이터)를 통해 지속적으로 검증하고, 최적의 매개변수를 찾는 방법으로 모델을 구성해야 합니다.

이러한 이유로 데이터의 구조나 형태는 지속해서 변경될 수 있습니다.

그러므로 데이터세트와 데이터로더를 활용해 코드 품질을 높이고 반복 및 변경되는 작업에 대해 더 효율적으로 대처해야 합니다.

## 모델/데이터세트 분리
파이토치의 모델(Model)은 인공 신경망 모듈을 활용해 구현됩니다.

모델은 데이터에 대한 연산을 수행하는 계층을 정의하고, 순방향 연산을 수행합니다.

클래스 구조를 활용해 복잡한 구조의 인공신경망을 모듈화해 빠르게 구추가혹 관리하기 쉬운 상태로 만듭니다.

모델 구현은 신경망 패키지의 모듈(Module) 클래스를 활용합니다.

새로운 모델 클래스를 생성하려면 모듈 클래스를 상속받아 임의의 서브 클래스(Sub Class)를 생성합니다.

이 클래스는 다른 모듈 클래스를 포함할 수 있으며 트리 구조(Tree Structure)로 중첩할 수 있습니다.

### 모듈 클래스

모듈 클래스는 초기화 메서드(__init__)와 순방향 메서드(forward)를 재정의 하여 활용합니다.

초기화 메서드에서는 신경망에 사용될 계층을 초기화 합니다.

순방향 메서드에서는 모델이 어떤 구조를 갖게 될지를 정의 합니다.

### 모델 평가

모델의 가중치와 편향을 확인해 이론적으로 학습이 잘 진행된 것을 알 수 있습니다.

no_grad 클래스는 기울기 계산을 비활성화하는 클래스입니다.

자동 미분 기능을 사용하지 않도록 설정해 메모리 사용량을 줄여 추론에 적합한 상태로 변경합니다.

추론에 적합한 상태로 변경했다면 모델을 평가 모드로 변경합니다.

모델 평가 모드는 eval 메서드로 변경할 수 있습니다.

모델을 평가모드로 변경하지 않으면 일관겅 없는 추론 결과를 반환하므로 평가 시 항상 선언하도록 주의 합니다.

평가 모드를 진행한 다음 다시 학습을 진행 하려는 경우 학습 모드로 변경해야 합니다.

### 데이터세트 분리

러닝머신에서 사용되는 **전체 데이터 세트(Original Dataset)** 는 두 가지 또는 세 가지로 나눌 수 있습니다.

전체 데이터세트는 **훈련용 데이터(Training Data), 테스트 데이터(Testing Data)** 로 분류 되고, 더 세분화하면 **검증용 데이터(Validation Data)** 까지 분리해 활용합니다.

**훈련용 데이터** 는 모델을 학습하는데 사용되는 데이터세트입니다.

지금까지 전체 데이터세트르 그대로 사용해 학습시키고 임의의 값을 입력하여 검증하거나 테스틀 진행합니다.

이러한 방법은 모델을 평가하는 데 적합한 방법이 아니며, 모델 학습에 사용되지 않은 새로운 데이터에 대해 평가해야 한다.

따라서 데이터세트를 분리하여 다음과 같은 검증과 테스트를 진행합니다.

**검증용 데이터** 는 학습이 완료된 모델을 검증(Validation)하기 위해 사용되는 데이터세트입니다.

주로 구조가 다른 모델의 성능 비교를 위해 사용되는 데이터세트를 의미합니다.

주로 구조가 다른 모델의 성능 비교를 위해 사용되는 데이터세트를 의미합니다.

모델은 계층이 다르거나 에포크, 학습률과 같은 하이퍼파리미터에 따라 학습 결과가 달라집니다.

계층이나 하이퍼파라미터 차이 등으로 인한 성능 비료를 위해 전체 데이터세트를 분리합니다.

**테스트 데이터** 는 검증용 데이터를 통해 결정된 성능이 가장 우수한 모델을 최종 테스트하기 위한 목적으로 사용되는 데이터세트입니다.

검증용 데이터에 의해 선택된 모델은 검증용 데이터에 과대적합된 모델이거나 검증용 데이터가 해당 모델에 적합한 형태의 데이터만 모여 있을 수 있다.

그러므로 기존 과정에서 평가해 보지 않은 새로운 데이터인 테스트 데이터로 최종 모델의 성능을 평가합니다.

훈련용 데이터는 모델 학습을 위한 데이터 집합, 검증용 데이터는 모델 선정을 위한 데이터 집합, 테스트 데이터는 최종 모델의 성능을 평가하기 위한 데이터 집합으로 볼 수 있습니다.

## 모델 저장 및 불러오기
파이토치의 모델은 직렬활(Serialize)와 역직렬화(Deserialize)를 통해 객체를 저장하고 불러올 수 있습니다.

모델을 저장하려면 파이썬 피클(Pickle)을 활용해 파이썬 객체 구조를 바이너리 프로토콜(Binary Protocols)로 직렬화 합니다. 

모델을 불러오면 저장된 객체 파일을 역직렬화해 현재 프로세스의 메모리에 업로드합니다.

이를 통해 모델을 통해 계산된 텐서나 매개변수를 불러올 수 있습니다.

모델을 불러오면 저장된 객체 파일을 역직렬화해 현재 프로세스의 메모리에 업로드합니다.

이를 통해 모델을 통해 계산된 텐서나 매개변수를 불러올 수 있습니다.

모델 학습ㄷ이 모두 완료된 이후에 모델을 저장하거나, 특정 에포크가 끝날 때마다 저장합니다.

모델 파일 확장자는 주로 .pt나 .pth로 저장합니다.

### 모델 전체 저장/불러오기

모델 전체를 저장하는 경우 학습에 사용된 모델 클래스의 구조와 학습 상태 등을 모두 저장합니다

모델의 계층 구조, 모델 매개변수 등이 모두 기록된 상태로 저장하기 때문에 모델 파일로도 동일한 구조를 구현 할 수 있습니다.

모델 저장 함수는 학습 결과를 저장하려는 **모델 인스턴스(model)** 와 학습결과 파일이 **생성될 경로(path)** 를 설정해 학습된 모델을 저장할 수 있습니다.

모델 불러오기 함수는 모델이 저장된 경로(path)를 볼러와 모델의 매개변수와 메타 데이터를 적용해 인스턴스를 생성합니다.

map_location 매개변수는 모델을 불러올 때 적용하려는 장치 상태를 의미합니다.

모델을 불러옿는 경우에도 동일한 형태의 클래스가 선언돼 있어야 합니다.

CustomModel 클래스를 선언하지 않으면 AttributeError 오류가 발생해 모델을 불러올 수 없습니다.

### 모델 상태 저장/불러오기

모델 전체를 저장하면 모델의 모든 정보를 저장하므로 모델 상태만 저장하는 것보다 더 많은 저장곤간이 필요합니다.

그러므로 모델의 매개변수만 저장하여 활용하는 방법이 있습니다.

모델 상태도 모델 저장 함수를 활용해 저장 할 수 있습니다.

차이점은 model 변수가 아닌 state_dict 메서드로 모델 상태를 저장할 수 있다는 것입니다.

모델 상태(torch.state_dict)는 모델에서 학습이 가능한 매개변수를 순서가 있는 딕셔너리(OrderedDict) 형식으로 반환합니다.

추론에 필요한 데이터만 가져와 저장하는 방식입니다.

모델 상태를 저장 했다면 모델 상태를 불러옵니다.

### 체크포인트 저장/불러오기

체크포인트(Checkpoint)는 학습 과정의 특정 지점마다 저장하는 것을 의미합니다.

데이터의 개수가 많고 깊은 구조의 모델을 학습하면 오랜 시간이 소요됩니다.

이러한 구조에서는 학습 시 예기지 못하게 오류가 발생하거나 시스템 리소스 과부화 등으로 학습이 정상적으로 마무리되지 않을 수 있습니다.

학습 과정에서 한 번에 전체 에포크를 반복하기 어렵거나 모종의 이유로 학습이 중단될 수 있습니다.

이러한 현상을 방지하기위해 일정 에포크마다 학습된 결과를 저장해 나중에 이어서 학습하게 할 수 있습니다.

체크포인트도 모델 저장 함수(torch.save)를 활용해 여러 상태를 저장할 수 있습니다.

다양한 정보를 저장하기 위해 딕셔너리 형식으로 값을 할당합니다.

학습을 이어서 진행하기 위한 목적으로 에포크(epoch), 모델 상태(model.state_dict), 최적화 상태(optimizer.state_dict) 등은 필수로 포함해야합니다.

모델 저장 및 불러오기는 사전에 학습된 모델을 사용하거나 공유하는 데 활용할 수 있습니다.

모델을 학습할 때는 모델을 특정 에포크마다 저장해 관리할 수 있게 코드를 구성해야 합니다.

## 활성화 함수(Activateion Function)
활성화 함수(Activation Function)란 인공 신경망에서 사용되는 은닉층을 활성화하기 위한 함수입니다.

여기서 활성화란 인공 신경망의 뉴런의 출력값을 선형에서 비선형으로 변환하는 것입니다.

즉 활성화 함수는 네트워크가 데이터의 복잡한 패턴을 기반으로 학습하고 결정을 내릴 수 있게 제어합니다.

활성화 함수는 가중치와 편향으로 이루어진 노드르 선형에서 비선형으로 갱신하는 역할을 합니다.

직관적으로 네트워크에 포함된 노드마다 전달돼야 하는 정보량이 다릅니다.

예를 들어 나의 출근 시간을 예측하기 위한 모델을 구현한다고 가정하면. 입력값이 일어난 시간 $(x_1)$과 기상 상태 $(x_2)$라면, 기상상태$(x_2)$ 값보다는 일어난 시간$(x_1)$이 더 영향력이 크다는 것을 직관적으로 알 수 있습니다.

그러므로 연산 과정에서 일어난 시간$(x_1)$은 더 많은 활성화(Activate)돼야 하며, 기상 상태 $(x_2)$는 비교적 비활성화(Deactivate)돼야 합니다.

활성화 함수는 비선형 구조를 가져 역전파 과정에서 미분값을 통해 학습이 진행될 수 있게 합니다.

활성화 함수가 선형 구조라면, 미분과정에서 항상 상수가 나오므로 학습을 진행하기 어렵습니다.

다시 말해 활성화 함수는 입력을 정규화(Normalization)하는 과정으로 볼 수 있습니다.

### 이진 분류

이진 분류란 규칙에 따라 입력된 값을 두 그룹으로 분류하는 작업을 의미합니다.

참(True) 또는 거짓(False)의 형태나 A 그룹 또는 B 그룹으로 데이터를 나누는 것입니다.

분류 결과가 맞는다면 1(True, A 그룹에 포함)을 반환하며, 아니라면 0(False, A 그룹에 포함되지 않음)을 반환합니다.

참 또는 거짓으로 결과를 분류하기 때문에 논리 회귀(로지스틱 회귀, Logistic Regression) 또는 논리 분류(Logistic Classfication)라고도 부릅니다.


### 시그모이드 함수

활성화 함수는 입력 데이터의 값을 정해진 수식에 따라 변환하는 식(Equation)을 의미합니다.

활성화 함수는 비선형으로 이뤄져 있습니다.

활성화 함수를 적용하면 입력값에 대한 출력값이 비선형으로 변환됩니다.

시그모이드 함수(Sigmoid Function)는 S자형 곡선 모양으로, 반환값은 0 ~ 1 또는 -1 ~ 1의 범위를 갖습니다.

시그모이드 함수의 계수가 0에 가까워질수록 완만한 경사를 갖게 되며, 0에서 멀어질수록 급격한 경사를 갖게 됩니다.

시그모이드 함수는 주로 로지스틱 회귀에 사용됩니다.

로지스틱 회귀는 독립변수(X)의 선형 결합을 활용하여 결과를 예측합니다.

종속 변수(Y)를 범주형 데이터를 대상으로 계산하기 때문에 해당데이터의 결과가 특정 분류로 나뉘게 됩니다.

시그모이드 함수를 통해 나온 출력값이 0.5 보다 낮으면 거짓(False)으로 분류하며, 0.5보다 크면 참(True)으로 분류합니다.

시그모이드 함수는 유연한 미분값을 가지므로, 입력에 따라 값이 급격하게 변하지 않는다는 장점이 있습니다.

또한 출력값의 범위가 0 ~ 1 사이로 제한됨으로써 정규화 중 기울기 폭주(Exploding Gradient) 문제가 발생하지 않고 미분 식이 단순한 형태를 지닙니다.

시그모이드 함수는 기울기 폭주를 방지하는 대신 기울기 소실(Vanishing Gradient) 문제를 일으킵니다.

신경망은 기울기를 이용해 최적화된 값을 찾아갑니다.

계층이 많아지면 점점 값이 0에 수렴되는 문제가 발생해 성능이 떨어집니다.

이 외에도 Y 값의 중심이 0이 아니므로 입력 데이터가 항상 양수인 경우라면, 기울기는 양수 또는 음수가 되어 기울기가 지그재그 형태로 변동하는 문제점이 발생해 학습 효율성을 감소시킬 수 있습니다.

### 이진 교차 엔트로피

이진 분류에 사용하는 시그모이드 함수의 예측값은 0 ~ 1 범위를 가집니다.

실제값 또한 0 ~ 1의 범위를 갖습니다.

평균 제곱 오차 함수를 이진 분류에 사용하면 좋은 결과를 얻기 어렵습니다.

임의의 예측값과 실젯값을 평균 제곱 오차 함수에 적용해 풀이하면 다음 수식과 같은 결과가 나옵니다.

$$
\begin{matrix}
MSE &=& (\hat{Y_i} - Y_i)^2\\
MSE &=&(0.99999999999 - 1)^2 \simeq 0\\
MSE &=&(0.00000000001 - 0)^2 \simeq 0\\
MSE &=&(0.00000000001 - 1)^2 \simeq 1
\end{matrix}
$$

평균제곱오차는 예측값과 실젯값의 차이가 작으면 계산되는 오차 또한 크기가 작아져 학습을 원활하게 진행하기 어렵습니다.

이러한 경우를 방지하고자 이진 교차 엔트로피(Binary Cross Entorpy, BCE)를 오차 함수로 사용합니다.

이진 교차 엔트로피는 로그 함수를 활용해 오차 함수를 구현합니다.

두가지 로그 함수를 교차해 오차를 계산합니다.

![Figure.png](image\Figure.png)

$$
BCE1 = -Y_i \cdot \log(\hat{Y_l})\\
BCE2 = -(1 - Y_i) \cdot \log(1-\hat{Y_l})
$$

$$
BCE = BCE1 + BCE2\\
= -(Y_i \cdot \log(\hat{Y_l}) + (1 - Y_i) \cdot \log(1-\hat{Y_l}))
$$

두 가지 로그 함수를 교차해 오차를 계산합니다.

$BCE1$ 수식은 실제값 $(Y_i = 1)$이 1일 때 적용하는 수식이며, $BCE2$ 수식은 실제값 $(Y_i = 0)$이 0일떄 적용하는 수식입니다.

이진 교차 엔트로피에 실제값이 1, 예측값이 1일 떄의 결과와 실제값이 1, 예측값이 0일때의 결과를 확인해 보면 다음 수식과 같이 표현이 됩니다.

$$
\begin{matrix}
BCE_{Y_i = 1, Y_l \simeq 1} &=& (Y_i \cdot \log(\hat{Y_l}) + (1 - Y_i) \cdot \log(1-\hat{Y_l}))\\
&=& -(1 \cdot \log(0.9999999999) + (1 - 1) \cdot \log(1 - 0.9999999999)\\
&\simeq& 0
\end{matrix}
$$

$$
\begin{matrix}
BCE_{Y_i = 1, Y_l \simeq 1} &=& (Y_i \cdot \log(\hat{Y_l}) + (1 - Y_i) \cdot \log(1-\hat{Y_l}))\\
&=& -(1 \cdot \log(0.0000000001) + (1 - 1) \cdot \log(1 - 0.0000000001)\\
&\simeq& 12
\end{matrix}
$$

기존의 평균 제곱 오차 함수는 명확하게 불일치하는 경우에도 높은 손실 값을 반환하지 않습니다.
하지만 로그 함수는 로그의 진수가 0에 가까워질수록 무한대로 발산하는 특성이 있습니다.

그러므로 로그 함수의 경우 불일치하는 비중이 높을수록 높은 손실(Loss) 값을 반환하게 됩니다.

로그 함수의 경우 한쪽으로는 무한대 이동하며 다른 한쪽으로는 0에 가까워지기 때문에 기울기가 0이 되는 지점을 찾기 위해 두가지 로그 함수를 하나로 합쳐 사용합니다.

두 수식을 합친다면 기울기가 0이되는 지점을 찾을 수 있게 됩니다.

최종적으로 반환되는 이진교차 엔트로피 함수는 오차를 계산하기 위해 각 손실갑스이 평균을 반환합니다.

다음 식은 이진교차 엔트로피 함수 기본형입니다.

$$
BCE = -\frac{1}{n}\sum_{i = 1}^{n}(Y_i \cdot \log(\hat{Y_l}) + (1 - Y_i) \cdot \log(1-\hat{Y_l}))
$$

### 비선형 활성화 함수(Non-linear Activations Function)

비선형 활성화 함수(Non-linear Activations Function)는 네트워크에 비선형을 적용하기 위해 인공 신경망에서 사용되는 함수입니다.

비선형 활성화 함수는 입력이 단순한 선형 조합이 아닌 형태로 출력을 생성하는 함수를 의미합니다.

선형적이 $ax + b$의 형식으로 사용하지 않는다는 것입니다.

왜나면 많은 실제 세계의 입출력 관계가 대부분 비선형적인 구조를 갖고있기 때문입니다.

eg) 사람의 나이와 키 사이의 관계는 선형관계가 아니고, 선형 활성화 함수를 사용하는 신경망은 이 관계를 정확하게 표현할 수 없습니다.

그러므로 비선형 활성화 함수를 사용해 입출력 간의 관계를 학습하고 더 정화한 예측을 할 수 있습니다.

이를 통해 네트워크가 학습 데이터의 복잡한 패턴과 관계를 학습할 수 있게 지원합니다.

### 계단 함수(Step Function)

계단함수는 이진 활성화 함수(Binary Activate Funcgin)라고도 하며, 퍼셉트론(Perceptron)에서 최초로 사용한 활성화 함수입니다

계단 함수의 입력값의 합이 임계값을 넘으면 0을 출력하고, 넘지 못 하면 1을 출력합니다.

![Figure_1.png](image\Figure_1.png)

$$
Step(x)=
\begin{cases}
1&if:&x\geq0
\\
0&else:& otherwise
\end{cases}
$$

딥러닝 모델에서는 사용되지 않는 함수로 임계값에서 불연속점(Point of discontinuity)을 가지므로 미분이 불가능해 학습을 진행할 수 없습니다.

또한, 역전파 과정에서 데이터가 극단적으로 변경되기 때문에 접합하지 않습니다.

### 임계값 함수

임계값 함수(Threshold Function)는 임계값(threshold)보다 크면 입력값(x)을 그대로 전달하고, 임계값보다 작으면 특정 값(value)으로 변경합니다.

선형 함수의 조합으로 볼 수 있습니다.

임계값 함수는 출력이 0 또는 1인 이진 분류 작업을 위해 신경망에서 자주 사용되는 효과적인 활성화 함수입니다.

하지만 입력에 대한 함수의 기울기를 계산할 수 없으므로 네트워크를 최적화하기 어려워 사용되지 않는 함수입니다.

![Figure_2.png](image\Figure_2.png)

$$
Threshold(x)=
\begin{cases}
x &if:& x > threshold\\
value &else:& otherwise
\end{cases}
$$

### 시그모이드 함수

시그모이드 함수(Sigmoid Function)는 모든 입력값을 0과 1사이의 값으로 매핑합니다.

이진 분류 신경망의 출력 계층에서 활성화 함수로 사용됩니다.

시그모이드 함수는 단순한 형태의 미분 식을 가지며, 입력값에 따라 출력값이 급격하게 변하지 않습니다.

출력값이 0 ~ 1의 범위를 가지므로 기울기 폭주 현상을 방지할 수 있지만, 출력값이 0 ~ 1의 범위를 가지는 만큼 매우 큰 입력값이 입력돼 최대 1의 값을 갖게 되어 기울기 소실이 발생합니다.

출력값의 중심이 0이 아니므로 입력 데이터가 항상 양수인 경우라면, 기울기는 모두 양수 또는 음수가 되어 기울기가 지그재그 형태로 변동하는 문제점이 발생해 학습 효율성을 감소시킵니다.

인공 신경망은 기울기를 이용해 최적화된 값을 찾아내는데, 계층이 많아지면 점점 값이 0에 수렴하는 문제가 발생해 성능이 떨어집니다.

시그모이드 함수는 주로 출력층에서만 사용합니다.

![Figure_3.png](image\Figure_3.png)

$$
Sigmoid(x) = \sigma(x)\frac{1}{1 + e^{-x}}
$$

### 하이퍼볼릭 탄젠트 함수

하이퍼볼릭 탄젠트 함수(Hyperbolic Tangent Function)는 시그모이드 함수와 유사한 형태를 지니지만, 출력값의 중심이 0입니다.

또한 출력값이 -1 ~ 1의 범위를 가지므로 시그모이드 함수에서 발생하지 않는 음수 값을 반환할 수 있습니다.

출력갑스이 범위가 더 넓고 다양한 형태로 활성화할 수 있으므로 기울기 소실이 비교적 덜 발생합니다.

하지만 하이퍼볼릭 탄젠트 함수도 시그모이드 함수와 마찬가지로 입력값(x)이 4보다 큰 경우 출력값이 1에 수렴하므로 동일하게 기울기 소실이 발생합니다.

![Figure_4.png](image\Figure_4.png)

$$
Thah(x) = \frac{e^x-e^{-x}}{e^x + e^{-x}}
$$

### ReLU함수

ReLU 함수(Rectified Linear Unit Function)는 0보다 작거나 같으며 0을 반환하며, 0보다 크면선 형함수에 값을 대입하는 구조를 갖습니다.

시그모이드 함수나 하이퍼볼릭 탄젠트 함수는 출력값이 제한되어 기울기 소실이 발생하지만, ReLU 함수는 선형 함수에 대입하므로 입력값이 양수라면 출력값이 제한 되지 않아 기울기 소실이 발생하지 않습니다.

수식 또한 매우 간단해 순전파나 역전파 과정의 연산이 매우 빠릅니다.

하지만 입력값이 음수인 경우 항상 0을 바환하므로 가중치나 편향이 갱신(Update)되지 않을 수 있습니다.

가중치의 합이 음수가 되면, 해당 노드는 더 이상 값을 갱신하지 않아 죽은 뉴런(Dead Neuron, Dying ReLU)이 됩니다.

딥러닝 네트워크에서 널리 사용되는 효과적인 활성화 함수입니다.

![Figure_5.png](image\Figure_5.png)

$$
ReLU(x) = 
\begin{cases}
x &if:& x>0\\
0 &else:& otherwise
\end{cases}
$$

### LeakyReLU

LeakyReLU 함수(Leaky Recified Linear Unit Function)은 음수 기울기(negative slope)를 제어하여, 죽은 뉴런 현상을 방지하기 위해 사용합니다.

양수인 경우 ReLU 함수와 동일하지만, 음수인 경우 작은 값이라도 출력시켜 기울기를 갱신하게 합니다.

작은 값을 출력시키려면 더 넓은 범위의 패턴을 학습할 수 있어 네트워크의 성능을 향상시키는데 도움이 될 수 있습니다.

![Figure_6.png](image\Figure_6.png)

$$
LeakyReLU(x) = 
\begin{cases}
x &if:& x > 0 \\
negative_slope \times x &else:&oherwise
\end{cases}
$$

### PReLU 함수

PReLU 함수(Parametric Rectified Linear Unit Function)는 LeakyReLU 함수와 형태가 동일 하지만, 음수 기울기(negative slope) 값을 고정값이 아닌, 학습을 통해 갱신되는 값으로 간주합니다.

PReLU 함수의 기울기(negative slope, a)는 지속해서 값이 변경 됩니다.

값이 지속해서 갱신되는 매개변수이므로, 학습 데이터세트에 영향을 받습니다.

$$
PReLU(x) =
\begin{cases}
x &if:& x > 0\\
a \times x &else:& otherwise
\end{cases}
$$

### ELU 함수

ELU 함수(Exponential Linear Unit Function)는 지수 함수를 사용해서 부드러운 곡선의 형태를 갖습니다.

기존 ReLU 함수와 변형 ReLU 변형 함수는 0에서 끊어지는데, ELU 함수는 음의 기울기에서 비선형 구조를 갖습니다.

그러므로 입력값이 0인 경우에도 출력값이 급변하지 않아, 경사하강법의 수렴 속도가 비교적 빠릅니다.

더 복잡한 연산을 진행하게 되므로 학습속도는 더 느려집니다.

하지만 ELU 함수는 데이터의 복잡한 패턴과 관계를 학습하는 네트워크의 능력을 향상 시키는데 도움이 될 수 있습니다.

![Figure_7.png](image\Figure_7.png)

$$
ELU(x) =
\begin{cases}
x &if:& x > 0\\
negative slope \times (e^x - 1) &else:& otherwise
\end{cases}
$$

### 소프트맥스 함수

소프트맥스 함수(Softmax Function)는 차원 벡터에서 특정 출력값이 $k$번째 클래스에 속할 확률을 계산합니다.

클래스에 속할 확률을 계산하는 활성화 함수이므로, 은닉층에서 사용하지 않고 출력층에서 사용됩니다.

네트워크의 출력을 가능한 클래스에 대한 확률 분포로 매핑합니다.

이 외에도 소프트민 함수(Softmin Function), 로그 소프트맥스 함수(Log Softmax Function) 등이 있습니다.

## 순전파와 역전파
순전파(Forward Propagation)란 순반향 전달(Forward Pass)이라고도 하며 입력이 주어지면 신경망의 출력을 계산하는 프로세스입니다.

입력 데이터를 기반으로 신경망을 따라 입력층부터 출력층까지 차례대로 변수를 계산하고 추론한 결과를 전달합니다.

네트워크에 입력값($x$)을 전달해 순전파 연산을 진행합니다.

이 과정에서 계층마다 가중치와 편향으로 계산된 값이 활성화 함수에 전달됩니다.

활성화 함수에서 출력값($\hat{y})$이 계산되고 이 값을 손실 함수에 실젯값($y$)과 함께 연산해 오차를 계산합니다.

다음 수식은 순전파 프로세스 수식입니다

$$
\hat{y} = activation(weight \times x + bias)
$$

역전파(Back Propagation)는 순전파 방향과 반대로 연산이 진행됩니다.

학습 과정에서 네트워크의 가중치와 편향은 예측된 출력값과 실제 출력값 사이의 오류를 최소화하기 위해 조정됩니다.

그러므로 순전파 과정을 통해 나온 오차를 활용해 각 계층의 가중치와 편향을 최적화합니다.

역전파 과정에서는 각각의 가중치와 편향을 최적화하기 위해 연쇄 법칙을 활용합니다.

새로 계산된 가중치는 최적화 알고리즘을 통해 실젯값과 예측값의 차이를 계산해 오차를 최소로 줄일 수 있는 가중치와 편향을 계산합니다.

순전파와 역전파는 네트워크가 입력값을 기반으로 예측을 수행할 수 있게 합니다.

학습을 반복할수록 모델의 성능을 향상시킬 수 있으므로 신경망 학습에서 중요한 프로세스 중 하나입니다.

![제목 없음.png](image\제목없음.png)

### 순전파 계산

첫 번째 계층의 가중합(Weighted Sum)을 계산합니다.

계산하려는 값은 $z_1, z_2$가 됩니다.

$z$는 가중합으로 입력값($x$)과 가중치($W$)의 곱을 모두 더한 값에 편향($b$)을 더한 값을 의미합니다.

$$
\begin{matrix}
z_1 &=& W_1x_1 \ + \ W_2x_2 + b_1\\
&=& 0.4352 \  \times \ 1 \ + \ 0.3545 \ \times \ 1 \ - \ 0.1419\\
&=& 0.6478 
\end{matrix}
$$

$$
\begin{matrix}
z_2 &=& W_3x_1 \ + \ W_4x_2 + b_2\\
&=& 0.1951\ \times \ 1 \ + \ 0.4835 \ \times \ 1 \ - \ 0.0439\\
&=& 0.7225
\end{matrix}
$$

가중합을 계산했다면 이 가중합에 활성화 함수를 적용합니다.

$$
\begin{matrix}
\sigma_1 &=& \frac{1}{1 + e^{z_1}}\\
&=& \frac{1}{1 + e^{-0.6478}}\\
&=& 0.6565
\end{matrix}
$$

$$
\begin{matrix}
\sigma_2 &=& \frac{1}{1 + e^{z_2}}\\
&=& \frac{1}{1 + e^{-0.7225}}\\
&=& 0.6732
\end{matrix}
$$

이렇게 첫 번째 층이 끝나고 두 번째 층을 계산합니다.

$$
\begin{matrix}
z_3 &=& W_5\sigma_1 \ + \ W_2\sigma_2 + b_3\\
&=& -0.1725 \  \times \ 0.6565 \ + \ 0.1129 \ \times \ 0.6731 \ - \ 0.3043\\
&=& -0.3415
\end{matrix}
$$

$$
\begin{matrix}
\sigma_3 &=& \frac{1}{1 + e^{-z_3}}\\
&=& \frac{1}{1 + e^{0.3415}}\\
&=& 0.4154
\end{matrix}
$$

이렇게 해서 나온 $\sigma_3$이 출력값이 됩니다.

### 오차계산

손실 함수는 이진 교차 엔트로피를 사용했으므로 실젯값($y = 0$)과 예측값($\hat{y} = 0.4154)$으로 오차를 계산합니다.

$$
\begin{matrix}
\mathcal{L} &=& -(y \log(\hat{y}) + (1 - y)\log(1 - \hat{y}))\\
&=& -(0\log0.4145) + (1-0)log(1-0.4145))\\
&=& -log0.5846 = 0.5368
\end{matrix}
$$

이렇게 하면 오차까지 계산이 된것입니다.

### 역전파 계산

역전파 과정에서는 계층의 역순으로 가중치와 편향을 갱신합니다.

$W_5, W_6, b_3$를 갱신한 다음에 $W_1, W_2, W_3, W_4, b_1, b_2$가 갱신됩니다.

모델의 학습은 오차가 작아지는 방향으로 갱신돼야 하기 때문에 미분값이 0에 가까워져야 합니다.

그러므로 갱신된 가중치와 편향의 기울기는 오차가 0이 되는 방향으로 진행합니다.

갱신된 가중치나 편향은 위에서 계산된 기울기를 감산해 변화가 없을 때 까지 반복합니다.

$$
W_n(t+1) = W_n(t)-\alpha\frac{\partial\mathcal{L}}{\partial W_n(t)}
$$

t는 가중치 갱신횟수, $\alpha$는 학습률을 의미 합니다.

이 수식을 활용해 지속해서 가중치를 갱신하면 $\frac{\partial\mathcal{L}}{\partial W_n(t)}$은 점점 0에 가까워 집니다

이는 오차가 0에 가까워지도록 가중치를 갱신하는 바업ㅂ입니다.

결국 $W_n(t+1) \simeq W_n(t)$가 되어 학습이 완료 됩니다.

순전파를 통해 오차를 계산하고 역전파 과정을 통해 오찻값이 0이 될 수 있게 가중치를 갱신합니다.

$$
\begin{matrix}
W_5(2) &=& W_1(1) - \alpha\frac{\partial\mathcal{L}}{\partial W_n(t)}\\
&=& -0.1725 - \frac{\partial\mathcal{L}}{\partial W_5(1)}
\end{matrix}
$$

$$W_5(1) = W_5$$

$$
\frac{\partial\mathcal{L}}{\partial W_5} = \frac{\partial\mathcal{L}}{\partial\sigma_3} \times \frac{\partial \sigma_3}{\partial z_3} \times \frac{\partial z_3}{\partial W_5}
$$

연쇄 법칙을 이용해 세 개의 항을 생성했습니다.

세 개의 항에는 $\mathcal{L}, \sigma_3, z_3, W_5$가 존재합니다.

이 값들은 순전파 풀이를 통해 식과 값을 알고있어 편미분을 진행 할 수 있습니다.

$$
\begin{matrix}
\frac{\partial \mathcal{L}}{\partial \sigma_3}
&=& -\frac{\partial}{\partial \sigma_3} \left( y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right) \\
&=& -\frac{\partial}{\partial \sigma_3} \left( y \log(\sigma_3) + (1 - y) \log(1 - \sigma_3) \right) \\
&=& -\left( \frac{y}{\sigma_3} - \frac{1 - y}{1 - \sigma_3} \right) \\
&=& \frac{\sigma_3 - y}{\sigma_3 (1 - \sigma_3)} \\
&=& \frac{\sigma_3}{\sigma_3 (1 - \sigma_3)} \\
&=& \frac{0.4154}{0.4154 (1 - 0.4154)} \\
&=& \frac{0.4154}{0.4154 (1 - 0.4154)} \\
&=& 1.7106
\end{matrix}
$$

$$
\begin{matrix}
\frac{\partial \sigma_3}{\partial z_3}
&=& -\frac{\partial}{\partial z_3} \left( \frac{1}{1 + e^{-z_3}} \right) \\
&=& \frac{e^{-z_3}}{(1 - e^{-z_3})^2} \\
&=& \frac{1}{1 + e^{-z_3}} \times \left(1 - \frac{1}{1 + e^{-z_3}} \right) \\
&=& \sigma_3 \times (1 - \sigma_3) \\
&=& 0.2428
\end{matrix}
$$

$$
\begin{matrix}
\frac{\partial z_3}{\partial W_5} &=& -\frac{\partial}{\partial W_5} \left( W_5 \sigma_1 + W_6 \sigma_2 + b_3 \right) \\
&=& \sigma_1 \\
&=& 0.6565
\end{matrix}
$$

$$
\begin{matrix}
\frac{\partial \mathcal{L}}{\partial W_5} &=& \frac{\partial \mathcal{L}}{\partial \sigma_3} \times \frac{\partial \sigma_3}{\partial z_3} \times \frac{\partial z_3}{\partial W_5} \\
&=& 1.7106 \times 0.2428 \times 0.6565 \\
&=& 0.2727
\end{matrix}
$$

$$
\begin{matrix}
W_5(2) &=& W_5(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_5(1)} \\
&=& -0.1725 - \alpha \frac{\partial \mathcal{L}}{\partial W_5(1)} \\
&=& -0.1725 - \frac{\partial \mathcal{L}}{\partial W_5} \\
&=& -0.1725 - 0.2727 \\
&=& -0.4452
\end{matrix}
$$

$W_5$의 가중치를 갱신 했습니다.

동일한 방식으로 $W_6, b_3$를 갱신할 수 있습니다.

$$
\begin{matrix}W_6(2) &=& W_6(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_6(1)} \\
&=& W_6(1) - \frac{\partial \mathcal{L}}{\partial \sigma_3} \times \frac{\partial \sigma_3}{\partial z_3} \times \frac \\ {\partial z_3}{\partial W_6} \\
&=& 0.1129 - 1.7106 \times 0.2428 \times 0.6732 \\
&=& -0.1667\end{matrix}
$$

$$
\begin{matrix}
b_3(2) &=& b_3(1) - \alpha \frac{\partial \mathcal{L}}{\partial b_3(1)} \\
&=& b_3(1) - \frac{\partial \mathcal{L}}{\partial \sigma_3} \times \frac{\partial \sigma_3}{\partial z_3} \times \frac{\partial z_3}{\partial b_3} \\
&=& 0.3043 - 1.7106 \times 0.2428 \times 0.0000 \\
&=& -0.7196
\end{matrix}
$$

이렇게 $W_5, W_6, b_3$의 가중치와 편향을 갱신 했습니다.

이젠 첫 번째 계층을 갱신해보겠습니다.

첫 번째 계층은 $W_1, W_2, W_3, b_1, b_2$이며 동일한 방식으로 진행하겠습니다.

$$
\begin{matrix}
W_1(2) &=& W_1(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_1(1)} \\
&=& W_1(1) - \frac{\partial \mathcal{L}}{\partial \sigma_1} \times \frac{\partial \sigma_1}{\partial z_1} \times \frac{\partial z_1}{\partial W_1} \\
&=& 0.4352 - \frac{\partial \mathcal{L}}{\partial W_1(1)} \times 0.2255 \times 1.0000
\end{matrix}
$$

$$
\begin{matrix}
\frac{\partial \mathcal{L}}{\partial W_1(1)} 
&=& \frac{\partial \mathcal{L}}{\partial \sigma_3} \times \frac{\partial \sigma_3}{\partial z_3} \times \frac{\partial z_3}{\partial \sigma_1} \\
&=& 1.7106 \times 0.2428 \times W_5 \\
&=& -0.0717
\end{matrix}
$$

오차 함수에도 연쇄 법칙을 적용하면 복잡한 연산을 진행하지 않고 결괏값을 확인 할 수 있습니다.

$$
\begin{align}
W_1(2) &= 0.4352 - \frac{\partial \mathcal{L}}{\partial W_1(1)} \times 0.2428 \times 1.0000 \\
&= 0.4352 + 0.0717 \times 0.2255 \times 1.0000 \\
&= 0.4514
\end{align}
$$

$W_1(2)$는 0.4352에서 0.4514로 갱신된 것을 확인할 수 있습니다.

나머지 가중치와 편향도 동일한 방식으로 갱신합니다.

$$
\begin{align}
W_6(2) &= W_2(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_2(1)} \\
&= W_2(1) - \frac{\partial \mathcal{L}}{\partial \sigma_2} \times \frac{\partial \sigma_2}{\partial z_2} \times \frac{\partial z_2}{\partial W_2} \\
&= 0.1848
\\
W_3(2) &= W_3(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_3(1)} \\
&= W_3(1) - \frac{\partial \mathcal{L}}{\partial \sigma_1} \times \frac{\partial \sigma_1}{\partial z_1} \times \frac{\partial z_1}{\partial W_3} \\
&= 0.3707
\\
W_4(2) &= W_4(1) - \alpha \frac{\partial \mathcal{L}}{\partial W_4(1)} \\
&= W_4(1) - \frac{\partial \mathcal{L}}{\partial \sigma_2} \times \frac{\partial \ sigma_2}{\partial z_2} \times \frac{\partial z_2}{\partial W_4} \\
&= 0.4732
\\
b_1(2) &= b_1(1) - \alpha \frac{\partial \mathcal{L}}{\partial b_4(1)} \\
&= b_1(1) - \frac{\partial \mathcal{L}}{\partial \sigma_1} \times \frac{\partial \sigma_1}{\partial z_1} \times \frac{\partial z_1}{\partial b_1} \\
&= -0.1257
\\
b_2(2) &= b_2(1) - \alpha \frac{\partial \mathcal{L}}{\partial b_2(1)} \\
&= b_2(1) - \frac{\partial \mathcal{L}}{\partial \sigma_2} \times \frac{\partial \sigma_2}{\partial z_2} \times \frac{\partial z_2}{\partial b_2} \\
&= 0.0336
\end{align}
$$

모든 가중치와 편향을 갱신하면 학습이 1회 진행된 것으로 볼 수 있습니다.

갱신된 가중치와 편향으로 다음번 학습을 진행합니다.

학습이 진행될수록 오차가 점차 감소하게 됩니다.

현재 풀이에선 배치 크기를 1로 가정하고 풀었습니다.

만양 배치크기가 1보다 크면 행렬 계산으로 풀이가 진행됩니다.

### 갱신 결과 비교

머신러닝은 순전파와 역전파를 반복해 최족의 가중치와 편향을 찾아갑니다.

특정한 횟수에 도달할 때까지 연산을 진행하거나 오찻값이 일정 이하로 떨어지게 되면 학습을 종료합니다.

$$
\begin{matrix}
\text{Layer1} \\
W_1(1) &= 0.4352 & W_1(2) &= 0.4514 \\
W_2(1) &= 0.1951 & W_2(2) &= 0.1848 \\
W_3(1) &= 0.3545 & W_3(2) &= 0.3707 \\
W_4(1) &= 0.4835 & W_4(2) &= 0.4732 \\
b_1(1) &= -0.1419 & b_1(2) &= -0.1257 \\
b_2(1) &= 0.0439 & b_2(2) &= 0.0336 \\
\\
\text{Layer2} \\
W_5(1) &= -0.1725 & W_5(2) &= -0.4452 \\
W_6(1) &= 0.1129 & W_6(2) &= -0.1667 \\
b_3(1) &= -0.3043 & b_3(2) &= -0.7196 \\
\end{matrix}
$$

결과를 보면 점점 값이 개선되는걸 알 수 있습니다.

계층 구조가 동일하더라도 오차 함수나 활성화 함수가 다르다면 결과를 얻을 수 있습니다.

예제에서 학습률을 비교적 큰 1로 주었음에도 Layer#1의 변화량은 Layer#2와 비교했을 때 크지 않은 것을 알 수 있습니다.

이 모델에서는 시그모이드 활성화 함수를 적용했습니다.

시그모이드는 출력값의 범위를 0 ~ 1로 제한하기 때문에 역전파 과정에서 0에 가까운 기울기가 곱해집니다.

그러므로 역전파 과정에서 입력층의 방향으로 값을 전달하는 과정에서 0으로 수렴하는 문제가 발생해 성능이 떨어집니다.

출력츠에 가까운 Layer#2는 변화량이 커지고 , 입력층에 가까운 Layer#1은 변화량이 미미해집니다.

이러한 이유로 깊은 모델의 은닉층에서는 시그모이드를 활성화 함수로 사용하지 않습니다.

## 퍼셉트론
퍼셉트론(Perceptron)이란 인공 신경망의 한 종류입니다.

출력이 0 또는 1인 작업을 의미하는 이진 분류 작업에 사용되는 간단한 모델입니다.

퍼셉트론은 신경세포(Neuron)가 신호를 전달하는 구조와 유사한 방식으로 구현됐습니다.

생물학적 신경망은 가지돌기(Dendrite)가 외부의 신경자극을 받아 신경체세포(Soma)에서 가중압력을 받아 신호를 전달합니다.

전달되는 신호는 축삭(Axon)을 통해 다른 신경 세포로 최종 신호를 전달합니다.

신경 세포에서 다른 신경세포로 신호를 전달할 때 시냅스(Synapse)라는 연결 부위를 통해 신호를 전달합니다.

이때 전달되는 신호를 어느 정도의 세기로 전달할지 결정하게 됩니다.

퍼셉트론은 이와 유사합니다.

가지돌기는 입력값(x)을 전달받는 역할을 합니다.

신경세포체는 입력값(x)을 토대로 특정연산을 진행했을 때 임곗값(Thresholde)보다 크면 전달하고, 작으면 전달하지 않습니다.

시냅스는 여러 퍼셉트론을 연결한 형태가 됩니다.

퍼셉트론은 TLU(Threshole Logic Unit) 형태를 기반으로 하며, 계단 함수를 적용해 결과를 반환합니다.

퍼셉트론은 입력값(x)과 노드의 가중치를 곱한 값을 모두 더했을 떄 임계값보다 크면 1을 출력하고, 작으면 0을 출력합니다.

그러므로 여러 입력값($x_1, x_2, x_3 \cdots x_x)$을 입력했을 때, 0이나 1또는 -1에서 1사이의 값을 출력하는 모델을 의미합니다. (계단함수를 적용)

### 단층 퍼셉트론

단층 퍼세븥론(Single Layer Perceptron)은 하나의 계층을 갖는 모델을 의미합니다.

입력을 통해 데이터가 전달되고 입력값(x)은 각각의 가중치와 함께 노드에 전달됩니다.

전달된 입력값(x)과 가중치를 곱한 값이 활성화 함수에 전달됩니다.

활성화 함수에서 출력값($\hat{y}$)이 계산되고 이 값을 손실 함수에 실젯값(y)과 함께 연산해 가중치를 변경합니다.

![image.png](image\image.png)

### 단층 퍼셉트론의 한계

단층 퍼셉트론은 AND, OR, NAND 게이트와 같은 구조를 갖는 모델은 쉽게 구현할 수 있습니다.

![Figure_8.png](image\Figure_8.png)

하나의 기울기로 값을 나누고, 그 기울기보다 위에 있거나 아래에 있다면 참 또는 거짓 값을 할 수 있습니다.

하지만 XOR 게이트처럼 하나의 기울기로 표현하기 어려운 구조에서는 단층 퍼셉트론을 적용하기가 어렵습니다.

XOR을 표현하려면 [(0, 0)] / [(0 ,1), (1, 0)] / [(1, 1)]의 구조로 삼등분해야 합니다.

[(0, 0), (1, 1)] / [(0 ,1), (1, 0)]의 구조로 이등분하려 한다면 직선이 아닌 곡선의 형태가 되어 학습이 어려워질 뿐만 아니라 과대적합 문제도 발생합니다.

이러한 문제를 해결하기 위해 다층 퍼셉트론을 활용합니다.

### 다층 퍼셉트론

다층 퍼셉트론(Mulit-Layer Perceptron, MLP)은 단층 퍼셉트론을 여러 개 쌓아 은닉층을 생성합니다.

다층 퍼셉트론은 은닉층이 한 개 이상인 퍼셉트론 구조를 의미합니다.

은닉층이 2개 이상 연결한다면 심층 신경망(Deep Neural Network, DNN)이라 부릅니다.

은닉층이 늘어날수록 더 복잡한 구조의 문제를 해결할 수 있습니다.

역전파 과정을 통해 모든 노드의 가중치와 편향을 수정해 오차가 작아지는 방향으로 학습이 진행됩니다.

1. 입력층부터 출력층까지 순전파를 진행
2. 출력값(예측값)과 실제값으로 오차 계산
3. 오차를 퍼셉트론의 역방향으로 보내면서 입력된 노드의 기여도 측정
    1. 손실 함수를 편미분해 기울기 계산
    2. 연쇄법칙(Chain Rule)을 통해 기울기를 계산
4. 입력층에 도달할 때까지 노드의 기여도 측정
5. 모든 가중치에 최적화 알고리즘 수행

앞선 내용을 정리하면, 은닉층의 수가 늘어날수록 더 복잡한 문제를 해결할 수 있다는 사실을 알게 됩니다.

![image (1).png](image\image_1.png)

계층이 세 개 이상이라면 비교적 더 정확한 값을 찾을 수있스습니다.

하지만 계층이 늘어날수록 갱신해야 하는 가중치나 편향이 늘어납니다.

최적의 가중치와 편향을 찾기 위해 많은 학습 데이터와 연산량을 필요로 하게 됩니다.

모델 구현에 있어 더 많은 양의 데이터를 수집해야 하며, 더 많은 학습 시간을 필요로 합니다.

더해 추론까지 걸리는 시간 및 비용이 증가합니다.

그래서 데이터와 모델의 정확도, 시간 및 비용을 고려해 적절한 모델을 설계해야합니다.

퍼셉트론은 많은 머신러닝 애플리케이션에 사용됩니다.

특히 이진 분류 작업에 여전히 사용되는 간단하고 효율적인 모델입니다.

하지만 데이터의 복잡한 패턴을 학습할 수 없으며, 선형으로 분리되지 않은 데이터를 분류할 수 없는 등 몇 가지 제한 사항이 있습니다.

이러한 제한으로 인해 보다 복잡한 작업에 더 접합한 고급 신경망 모델이 개발됐습니다.
